{"cells":[{"cell_type":"markdown","metadata":{"id":"sgXJNMd2coya"},"source":["access to the data_storage.py: https://drive.google.com/file/d/1-6_x0L6_yxaj3oxwmGJoYbn6luBgcnwX/view?usp=drive_link\n","access to the code below as script: https://drive.google.com/file/d/1-9158gNZZzkJLlUvEiqUkq6S7cVNLMf4/view?usp=sharing"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":32847,"status":"ok","timestamp":1721759319768,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"tKVguRub1wd_"},"outputs":[],"source":["import ee\n","# @title Authenticate to the Earth Engine servers\n","ee.Authenticate()\n","# Initialize the Earth Engine object with Google Cloud project ID\n","project_id = 'ee-janet' # change here\n","ee.Initialize(project=project_id)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24159,"status":"ok","timestamp":1721759343925,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"v7Qm72MpXi0f","outputId":"10945b6a-ccb7-4c28-c89d-d55bd8e575b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":337,"status":"error","timestamp":1721766276297,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"0aaqStUK6zab","outputId":"4afa3a53-626c-4d29-c40b-c6abad09376c"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'scripts.extract_s2_planet_ncfi'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5ef2e8cbebcd>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiPolygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_storage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mds\u001b[0m  \u001b[0;31m# Importing the data storage script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_s2_planet_ncfi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mesp\u001b[0m \u001b[0;31m#import extract s2_planet_ncfi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scripts.extract_s2_planet_ncfi'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["# @title Lib imports:\n","#import ee\n","#print('Using EE version ', ee.__version__)\n","import folium\n","#print('Using Folium version ', folium.__version__)\n","from os import MFD_HUGE_1MB\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from typing import Dict, Iterable, List, Tuple\n","#from google.colab import auth\n","import datetime as dt\n","import time\n","import geopandas as gpd\n","from shapely.geometry import shape, Polygon, MultiPolygon\n","import scripts.data_storage as ds  # Importing the data storage script\n","import scripts.extract_s2_planet_ncfi as esp #import extract s2_planet_ncfi"]},{"cell_type":"markdown","metadata":{"id":"k228xy6ZbMZ8"},"source":["## Clean the raw data for all years"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1721759604501,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"ErqNlGZZ4LsL"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/clean_data_no_bands')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9095,"status":"ok","timestamp":1721759629361,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"VLaM3Ohp4ubx"},"outputs":[],"source":["shp_2018 = gpd.read_file('land_cover_2018.shp')#.apply(lambda x: x.astype(str).apply(capitalize_first))\n","shp_2019 = gpd.read_file('land_cover_2019.shp')#.apply(lambda x: x.astype(str).apply(capitalize_first))\n","shp_2020 = gpd.read_file('land_cover_2020.shp')#.apply(lambda x: x.astype(str).apply(capitalize_first))\n","shp_2020 = shp_2020[shp_2020['ID'].notna()]\n","shp_2023 = gpd.read_file('land_cover_2023.shp')#.apply(lambda x: x.astype(str).apply(capitalize_first))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1721759721700,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"JR88G3rd4H94","outputId":"05ee4da7-3cdf-46f5-985a-d9a4ce2a3264"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"shp_2023\",\n  \"rows\": 4961,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4961,\n        \"samples\": [\n          \"4380\",\n          \"394\",\n          \"1165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Crops\",\n          \"Noncrop\",\n          \"Fallow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Groundnut_Mixed\",\n          \"Sesame\",\n          \"Cashew\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Tree_Crops\",\n          \"Vegetables\",\n          \"Cereals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2023\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"geometry\",\n      \"properties\": {\n        \"dtype\": \"geometry\",\n        \"num_unique_values\": 4961,\n        \"samples\": [\n          \"POLYGON ((-14.170117926724865 13.208891839244075, -14.17002872725767 13.208909648646586, -14.169935094477554 13.20891413453239, -14.169899450196784 13.208936409377651, -14.169350955002955 13.209070212231499, -14.169110224269351 13.209137077893528, -14.169101268916592 13.209132598524992, -14.169092313564395 13.209110337384077, -14.169074491528537 13.209061257310491, -14.169056669494907 13.209021111079913, -14.169043280804454 13.208989907403382, -14.169029892115255 13.208958703731188, -14.169016592094122 13.208923028171078, -14.168998681400963 13.208891820767583, -14.168985381382747 13.208865079039583, -14.16897642603785 13.208847198933992, -14.168949648673308 13.2088026592664, -14.168931826655333 13.208766979986006, -14.168909571302686 13.208735758892336, -14.16887836061481 13.208717926047342, -14.16885158326874 13.208695635016658, -14.16880255059182 13.208659990505742, -14.168762384596024 13.20863321135049, -14.168726740609259 13.208606435937428, -14.168695529961521 13.208584136154343, -14.16866431932063 13.208552902557281, -14.168633108686597 13.208521754858936, -14.168606331386721 13.208490529990453, -14.168583987418499 13.208454846955087, -14.168557298794388 13.208392434705551, -14.168539388159095 13.208356760418983, -14.168521566192553 13.208258630506826, -14.168561732120306 13.208240826650904, -14.16877577326003 13.208164981519545, -14.168869405276654 13.208151648529203, -14.169123612966114 13.20806693317343, -14.169150301696536 13.208084762190904, -14.169168123741903 13.208057990859551, -14.169212723198546 13.208044576683394, -14.169252889321575 13.208053488155299, -14.16927966674323 13.208129295678152, -14.169333132934675 13.208209617479724, -14.169382165794586 13.208307712202402, -14.169449109419052 13.208499464726351, -14.169939616513815 13.208356722244767, -14.170033249296905 13.20861981987641, -14.170019860514486 13.208615331860914, -14.17000203836236 13.208619854813419, -14.169993082953425 13.20862430927163, -14.169984216212464 13.208646540395428, -14.169984216212464 13.208655474170024, -14.169993082953425 13.20866889223993, -14.170006471733323 13.208673294355348, -14.170019860514486 13.208673315483706, -14.17002872725767 13.2086643991143, -14.170042116040928 13.208655486468201, -14.17008228239826 13.20876696434164, -14.170077849024928 13.208807071757965, -14.170095671186557 13.208807101574656, -14.170117926724865 13.208891839244075))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"shp_2023"},"text/html":["\n","  <div id=\"df-bcb4dd7b-30cc-484e-8c02-5b3b577a0765\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Class</th>\n","      <th>Name</th>\n","      <th>Sub_class</th>\n","      <th>Year</th>\n","      <th>geometry</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Crops</td>\n","      <td>Cashew</td>\n","      <td>Tree_Crops</td>\n","      <td>2023</td>\n","      <td>POLYGON ((-16.35692 13.85091, -16.35663 13.851...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Crops</td>\n","      <td>Cashew</td>\n","      <td>Tree_Crops</td>\n","      <td>2023</td>\n","      <td>POLYGON ((-16.37232 13.82824, -16.37223 13.828...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Crops</td>\n","      <td>Cashew</td>\n","      <td>Tree_Crops</td>\n","      <td>2023</td>\n","      <td>POLYGON ((-16.42729 13.75103, -16.42726 13.751...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Crops</td>\n","      <td>Cashew</td>\n","      <td>Tree_Crops</td>\n","      <td>2023</td>\n","      <td>POLYGON ((-16.42793 13.76519, -16.42789 13.765...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Crops</td>\n","      <td>Cashew</td>\n","      <td>Tree_Crops</td>\n","      <td>2023</td>\n","      <td>POLYGON ((-16.42801 13.76906, -16.42797 13.769...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcb4dd7b-30cc-484e-8c02-5b3b577a0765')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bcb4dd7b-30cc-484e-8c02-5b3b577a0765 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bcb4dd7b-30cc-484e-8c02-5b3b577a0765');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-796b4176-8da2-417e-bdb0-98d28cfae3b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-796b4176-8da2-417e-bdb0-98d28cfae3b1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-796b4176-8da2-417e-bdb0-98d28cfae3b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["  ID  Class    Name   Sub_class  Year  \\\n","0  1  Crops  Cashew  Tree_Crops  2023   \n","1  2  Crops  Cashew  Tree_Crops  2023   \n","2  3  Crops  Cashew  Tree_Crops  2023   \n","3  4  Crops  Cashew  Tree_Crops  2023   \n","4  5  Crops  Cashew  Tree_Crops  2023   \n","\n","                                            geometry  \n","0  POLYGON ((-16.35692 13.85091, -16.35663 13.851...  \n","1  POLYGON ((-16.37232 13.82824, -16.37223 13.828...  \n","2  POLYGON ((-16.42729 13.75103, -16.42726 13.751...  \n","3  POLYGON ((-16.42793 13.76519, -16.42789 13.765...  \n","4  POLYGON ((-16.42801 13.76906, -16.42797 13.769...  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["shp_2023.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1721759750971,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"tZvN1x7R4M6H","outputId":"5d18833f-a8f5-4785-f638-7af4882cc43a"},"outputs":[{"data":{"text/plain":["array(['Millet_Cowpea', 'Millet_Bissap', 'Groundnut_Mixed', 'Millet',\n","       'Cowpea', 'Sorghum', 'Fallow', 'Maize', 'Fonio', 'Laterite_Road',\n","       'Groundnut', 'Vegetation', 'Millet_Pasture', 'Built_Up',\n","       'Paved_Road', 'Bissap', 'Cowpea_Bissap', 'Watermelon',\n","       'Sandy_Road', 'Maize_Other', 'Maize_Millet', 'Maize_Bissap',\n","       'Rice', 'Cotton', 'Track', 'Maize_Gum', 'Okra', 'Sesame',\n","       'Bare_Soil', 'Quarry', 'School', 'Cowpea_Pasture',\n","       'Cowpea_Soybean', 'Cemetery', 'Sesame_Bissap', 'Sesame_Millet',\n","       'Okra_Maize', 'Sugarcane', 'Bissap_Groundnut',\n","       'Cotton_Other_Crops', 'Millet_Maize', 'Maize_Sorghum',\n","       'Millet_Groundnut'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["shp_2020.Name.unique()"]},{"cell_type":"markdown","metadata":{"id":"NTNjGBopoF1u"},"source":["### Extracting remote sensing indices and normalized band values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxo4BmHOlmq-"},"outputs":[],"source":["class Sentinel2Processor:\n","    def __init__(self, year, months, indices, data_fc):\n","        self.year = year\n","        self.months = months\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_indices(self, image):\n","        index_functions = {\n","            'NDVI': lambda img: img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n","        }\n","\n","        for index in self.indices:\n","            if index in index_functions:\n","                image = image.addBands(index_functions[index](image))\n","\n","        return image\n","\n","    def normalize_band(self, image, band_name):\n","        band = image.select(band_name).toFloat()\n","        min_max = band.reduceRegion(\n","            reducer=ee.Reducer.minMax(),\n","            geometry=image.geometry(),\n","            scale=10,\n","            maxPixels=1e13\n","        )\n","        min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","        max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","        normalized = band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name))#.cat('_n'))\n","        return normalized\n","\n","    def process_image(self, image):\n","        with_indices = self.calculate_indices(image)\n","        bands_to_normalize = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12']\n","        normalized_bands = ee.Image.cat([self.normalize_band(with_indices, band) for band in bands_to_normalize])\n","        return normalized_bands.addBands(with_indices.select(self.indices))\n","\n","    def process_all_months(self):\n","        processed_images = []\n","\n","        for month_index, month in enumerate(self.months):\n","            start_date = ee.Date.fromYMD(self.year, month, 1)\n","            end_date = ee.Date.fromYMD(self.year, ee.Number(month).add(1), 1)\n","\n","            collection = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\") \\\n","                .filterBounds(self.data_fc) \\\n","                .filterDate(start_date, end_date) \\\n","                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n","\n","            num_images = self.retry_function(lambda: collection.size().getInfo())\n","            print(f\"Number of images for {month}/{self.year}: {num_images}\")\n","\n","            processed_collection = collection.map(self.process_image)\n","            composite = processed_collection.median().toFloat()\n","            # Create the date string in the format \"MMYY\"\n","            date_str = f'{month:02d}{str(self.year)[-2:]}'\n","\n","            def rename_band(band_name):\n","                return ee.String('norm_').cat(band_name).cat('_').cat(date_str)\n","\n","            new_band_names = composite.bandNames().map(rename_band)\n","            print(new_band_names.getInfo())\n","            composite = composite.rename(new_band_names)\n","\n","            processed_images.append(composite)\n","\n","            # Add a delay between processing months\n","            time.sleep(random.uniform(5, 10))\n","\n","        return ee.ImageCollection(processed_images).toBands()\n","\n","    def retry_function(self, func, max_retries=10, initial_delay=1, factor=2):\n","        \"\"\"Retry a function with exponential backoff.\"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=10,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='clean_data_with_bands_s2'):\n","        combined_image = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","        print(data_with_bands.getInfo())\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(Sentinel2Processor):\n","    def __init__(self, subclass_df, year, months, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, months, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = []\n","            for polygon in geometry.geoms:\n","                polygons.append(list(polygon.exterior.coords))\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    import os\n","\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/clean_data_with_bands_s2')\n","\n","    # Years to process\n","    years = [2018]#, 2019, 2020, 2023]  # Replace with your desired years\n","    months = [8]#, 9, 10, 11]  # Add or reduce months\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","      #  2019: shp_2019,\n","       # 2020: shp_2020,\n","      #  2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            #subclass_df= subclass_df.apply(lambda x: x.astype(str).apply(capitalize_first))\n","            processor = SubclassProcessor(subclass_df, year, months, indices, subclass_name)\n","            try:\n","                processor.export_to_drive(f'data_{year}_with_bands_subclass_{subclass_name}')\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))\n"]},{"cell_type":"markdown","metadata":{"id":"HOi2IuwIzlig"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOSymWj068fs"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2ZRU1q_OzWU"},"outputs":[],"source":["# Main execution\n","if __name__ == \"__main__\":\n","    import os\n","    import ee\n","\n","    # Initialize Earth Engine\n","    ee.Initialize()\n","\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/clean_data_with_bands_s2')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","    months = [8, 9, 10, 11]  # Add or reduce months as needed\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Create a dictionary to store the FeatureCollections for each year and subclass\n","    data_fc = {\n","        2018: {\n","            'Cereals': clean_raw_data_2018_Cereals,\n","            'Legumes': clean_raw_data_2018_Legumes,\n","            'Noncrop': clean_raw_data_2018_Noncrop,\n","            'Tree_Crops': clean_raw_data_2018_Tree_Crops,\n","            'Vegetables': clean_raw_data_2018_Vegetables\n","        },\n","        2019: {\n","            'Cereals': clean_raw_data_2019_Cereals,\n","            'Legumes': clean_raw_data_2019_Legumes,\n","            'Noncrop': clean_raw_data_2019_Noncrop,\n","            'Vegetables': clean_raw_data_2019_Vegetables\n","        },\n","        2020: {\n","            'Bare_Built_Up': clean_raw_data_2020_Bare_Built_Up,\n","            'Cereals': clean_raw_data_2020_Cereals,\n","            'Fallow': clean_raw_data_2020_Fallow,\n","            'Legumes': clean_raw_data_2020_Legumes,\n","            'Noncrop': clean_raw_data_2020_Noncrop,\n","            'Other_Vegetation': clean_raw_data_2020_Other_Vegetation,\n","            'Tree_Crops': clean_raw_data_2020_Tree_Crops,\n","            'Vegetables': clean_raw_data_2020_Vegetables\n","        },\n","        2023: {\n","            'Cereals': clean_raw_data_2023_Cereals,\n","            'Fallow': clean_raw_data_2023_Fallow,\n","            'Legumes': clean_raw_data_2023_Legumes,\n","            'Noncrop': clean_raw_data_2023_Noncrop,\n","            'Tree_Crops': clean_raw_data_2023_Tree_Crops,\n","            'Vegetables': clean_raw_data_2023_Vegetables\n","        }\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, fc in data_fc[year].items():\n","            processor = esp.SubclassProcessor(year, months, indices, fc)\n","            try:\n","                processor.export_to_drive(f'data_{year}_with_bands_subclass_{subclass_name}')\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XkSqiNyO0kE"},"outputs":[],"source":["\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/clean_data_with_bands_s2')\n","\n","    # Years to process\n","    years = [2018,2019, 2020, 2023]  #2019, 2020, 2023 # Replace with your desired years\n","    months = [8, 9, 10, 11]  # add or reduce months\n","    indices = ['NDVI']  # add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, months, indices, subclass_name)\n","            try:\n","                processor.export_to_drive(f'data_{year}_with_bands_subclass_{subclass_name}')\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"markdown","metadata":{"id":"-F4DJtEZXRmE"},"source":["Planet NICFI"]},{"cell_type":"markdown","metadata":{"id":"g4SYuDKd84nw"},"source":["$`Biannual Collection`\n","   PS_Tropical_Normalized_Analytic_Biannual\n","\n","*  December 2015,  June 2016, December 2016, June 2017, December 2017,   June 2018,December 2018, June 2019, December 2019, June 2020\n","                              \n","                          \n","\n","$`Monthly Collection`\n","  PS_Tropical_Normalized_Analytic_Monthly\n","* September 2020, October 2020,November 2020, December 2020,January 2021,February 2021, March 2021,April 2021,May 2021,June 2021,July 2021,August 2021, September 2021,October 2021,November 2021,December 2021,January 2022, February 2022,March 2022,  April 2022\n","                       "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3z_WMDcY9IHi"},"outputs":[],"source":["# Set working directory\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data')\n","\n","# Load shapefiles\n","shp_2018 = gpd.read_file('clean_data_no_bands/land_cover_2018.shp')\n","shp_2019 = gpd.read_file('clean_data_no_bands/land_cover_2019.shp')\n","shp_2020 = gpd.read_file('clean_data_no_bands/land_cover_2020.shp')\n","shp_2023 = gpd.read_file('clean_data_no_bands/land_cover_2023.shp')\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","\n","            # Check if min and max are valid\n","            is_valid = min_val.isNumber().And(max_val.isNumber()).And(max_val.neq(min_val))\n","\n","            normalized_band = ee.Image(ee.Algorithms.If(\n","                is_valid,\n","                band.subtract(min_val).divide(max_val.subtract(min_val)),\n","                band  # If normalization fails, return the original band\n","            )).rename(ee.String(band_name).cat('_norm'))\n","\n","            return normalized_band\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size().getInfo()\n","            if count == 0:\n","                print(f\"No images found for the period: {start_date} to {end_date}\")\n","                continue\n","\n","            normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","            ndvi_collection = normalized_collection.map(self.calculate_ndvi)\n","\n","            print(f\"Number of images: {ndvi_collection.size().getInfo()}\")\n","\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            composite = ndvi_collection.median().select(bands)\n","\n","            # Add a date band to the composite\n","            date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","            composite_with_date = composite.addBands(date_band)\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed for any date range\")\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","            except ValueError as e:\n","                print(f\"No data available for {year}, subclass {subclass_name}: {str(e)}\")\n","            except Exception as e:\n","                print(f\"Unexpected error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2084854,"status":"ok","timestamp":1721582630567,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"wIWs8JyKMV5F","outputId":"58422ab7-dced-409d-a517-f1784faeb1c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 6IOPORXOQY5H52ZUZU3KYNMJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: POTMARXPEOQZ4L6OPRQSWPYH\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: VNFFL6KUA3X5I53MZWMUR5SK\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: GXQR2K4RAHPO5ZYJT3DSVYLO\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: CALONKYMKLBAEFHETA2LN5A2\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: DERL7PNSCH6OUHBEDMCP3HDP\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: GT6NDUDTBR2ILCBBEBQSKZFI\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: 5C7AZUXCS4RL2CTFOC2UCXR6\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: CIOPQNUDST6CKIEYJFEMX4SC\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: PAZI7A6FKWY3Z6GS5CRC2YWZ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: S2X3OYRJ6C3BKRFKFASEAFU6\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: IIUZAOKODHK7UJCPDRR26RYU\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: YUECZZEFCPRNCV6ZL3OV2ZA3\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: CCJPQZQ4VO2MLKS4OXWYMQYL\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: Y3E2CJTHRB2CHTT4GAACXVUJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: EFB27IZG6DJFZVP7GEN3FNH5\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: DS67ADPR6KCFKHCUGCT7SIKS\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: NW5MXUNQIJPFV5XGX4XB4B4H\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: VU3RME62ON4LZDA2OE5JU4R4\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: 4ABPFZ6DRC2KEFLS7KQO6ZW6\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: JAETCMBFVTN42CJW7KKJSANR\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: 7MFRU4A5XU2PARQX2KQC4VQR\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-08-01 to 2023-08-31\n","Number of images: 1\n","Processing period: 2023-09-01 to 2023-09-30\n","Number of images: 1\n","Processing period: 2023-10-01 to 2023-10-31\n","Number of images: 1\n","Processing period: 2023-11-01 to 2023-11-30\n","Number of images: 1\n","Started export task: LJLZACFXKYFZ6VCZNZ6HHB4C\n","Check your Earth Engine Tasks panel to monitor progress.\n"]}],"source":["\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","\n","            # Check if min and max are valid\n","            is_valid = min_val.lt(max_val)\n","\n","            normalized_band = ee.Image(ee.Algorithms.If(\n","                is_valid,\n","                band.subtract(min_val).divide(max_val.subtract(min_val)),\n","                band  # If normalization fails, return the original band\n","            )).rename(ee.String(band_name).cat('_norm'))\n","\n","            return normalized_band\n","\n","        normalized_bands = ee.ImageCollection(ee.List(band_names).map(lambda band: normalize_band(ee.String(band))))\n","        normalized_image = normalized_bands.toBands().rename(band_names)\n","\n","        return image.addBands(normalized_image)\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size()\n","\n","            def process_collection(count):\n","                normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","                ndvi_collection = normalized_collection.map(self.calculate_ndvi)\n","\n","                print(f\"Number of images: {count.getInfo()}\")\n","\n","                composite = ndvi_collection.median()\n","\n","                # Add a date band to the composite\n","                date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","                return composite.addBands(date_band)\n","\n","            composite_with_date = ee.Algorithms.If(\n","                count.gt(0),\n","                process_collection(count),\n","                None\n","            )\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        # Filter out None values\n","        processed_images = [img for img in processed_images if img is not None]\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed for any date range\")\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    import geopandas as gpd\n","\n","    # Set up your Google Drive folder\n","    drive_folder = '/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi'\n","    if not os.path.exists(drive_folder):\n","        os.makedirs(drive_folder)\n","    os.chdir(drive_folder)\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","\n","\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","            except ValueError as e:\n","                print(f\"No data available for {year}, subclass {subclass_name}: {str(e)}\")\n","            except Exception as e:\n","                print(f\"Unexpected error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":398636,"status":"error","timestamp":1721578983468,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"Zc5QMAx2FDen","outputId":"e4dfb2a4-3830-46fe-d690-3c0224d11243"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: K55JY52IN7H5X3IR46AQR2QZ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: U75JJWWRAY567E6GNHZBXGRT\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: KGEKDOKDSK22H77HRZBC7VPQ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: XU2RLRTEZIT6TKFCUPWZCS4W\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: CWTNW7O5TPTXNF45RA73JYEC\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-050ca007cf62>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data_{year}_with_bands_subclass_{subclass_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-050ca007cf62>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mExport\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madded\u001b[0m \u001b[0mbands\u001b[0m \u001b[0mto\u001b[0m \u001b[0mGoogle\u001b[0m \u001b[0mDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mimage_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-050ca007cf62>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprocessed_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomposite_with_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Filter out None values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","\n","            # Check if min and max are valid\n","            is_valid = min_val.lt(max_val)\n","\n","            normalized_band = ee.Image(ee.Algorithms.If(\n","                is_valid,\n","                band.subtract(min_val).divide(max_val.subtract(min_val)),\n","                band  # If normalization fails, return the original band\n","            )).rename(ee.String(band_name).cat('_norm'))\n","\n","            return normalized_band\n","\n","        normalized_bands = ee.ImageCollection(ee.List(band_names).map(lambda band: normalize_band(ee.String(band))))\n","        normalized_image = normalized_bands.toBands().rename(band_names)\n","\n","        return image.addBands(normalized_image)\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size()\n","\n","            def process_collection(count):\n","                normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","                ndvi_collection = normalized_collection.map(self.calculate_ndvi)\n","\n","                print(f\"Number of images: {count.getInfo()}\")\n","\n","                composite = ndvi_collection.median()\n","\n","                # Add a date band to the composite\n","                date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","                return composite.addBands(date_band)\n","\n","            composite_with_date = ee.Algorithms.If(\n","                count.gt(0),\n","                process_collection(count),\n","                None\n","            )\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        # Filter out None values\n","        processed_images = [img for img in processed_images if img is not None]\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed for any date range\")\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","            except ValueError as e:\n","                print(f\"No data available for {year}, subclass {subclass_name}: {str(e)}\")\n","            except Exception as e:\n","                print(f\"Unexpected error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":368528,"status":"error","timestamp":1721578566054,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"z6V-qENjCLua","outputId":"daa146dc-7387-460e-fb14-208dc156a3d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: BBG6TPJSXAKURVKLAEKCCB6B\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: ZJLSFN6JU7ZVVF2AGK5OKSJT\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: OIHRIXDJFYABY2TGRIHDBDNS\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 5ZA6IAHIPYUDGQ5LPZBRG2NG\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: XTCQVNLRF6PGTKFELVJ4FK5L\n","Check your Earth Engine Tasks panel to monitor progress.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-133bdd134dd4>\u001b[0m in \u001b[0;36m<cell line: 159>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# Add a delay between processing subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Set working directory\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data')\n","\n","# Load shapefiles\n","shp_2018 = gpd.read_file('clean_data_no_bands/land_cover_2018.shp')\n","shp_2019 = gpd.read_file('clean_data_no_bands/land_cover_2019.shp')\n","shp_2020 = gpd.read_file('clean_data_no_bands/land_cover_2020.shp')\n","shp_2023 = gpd.read_file('clean_data_no_bands/land_cover_2023.shp')\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","\n","            # Check if min and max are valid\n","            is_valid = min_val.lt(max_val)\n","\n","            normalized_band = ee.Image(ee.Algorithms.If(\n","                is_valid,\n","                band.subtract(min_val).divide(max_val.subtract(min_val)),\n","                band  # If normalization fails, return the original band\n","            )).rename(ee.String(band_name).cat('_norm'))\n","\n","            return normalized_band\n","\n","        normalized_bands = ee.List(band_names).map(lambda band: normalize_band(ee.String(band)))\n","        return image.addBands(normalized_bands)\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size()\n","\n","            def process_collection(count):\n","                normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","                ndvi_collection = normalized_collection.map(self.calculate_ndvi)\n","\n","                print(f\"Number of images: {count.getInfo()}\")\n","\n","                composite = ndvi_collection.mosaic()\n","\n","                # Add a date band to the composite\n","                date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","                return composite.addBands(date_band)\n","\n","            composite_with_date = ee.Algorithms.If(\n","                count.gt(0),\n","                process_collection(count),\n","                None\n","            )\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        # Filter out None values\n","        processed_images = [img for img in processed_images if img is not None]\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed for any date range\")\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","            except ValueError as e:\n","                print(f\"No data available for {year}, subclass {subclass_name}: {str(e)}\")\n","            except Exception as e:\n","                print(f\"Unexpected error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":668547,"status":"error","timestamp":1721577813488,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"_xH3o61F_j-0","outputId":"8cd898f5-56bd-4341-9d72-f3ec58c3c4e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: YGEAOLK4YNRFBZGX6WNH5MKH\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 4EIX54B34JG7EQKQ4XBMVLJG\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 2YMVJYLFECFNHG4IAMRTMPNO\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 7YIJH5EJAWUQBT7FYEYY4EGD\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: FFWHVRQEYZP3IEETADFT75MZ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: MD2GQ4XAQAU7KMQF42MRJAJD\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: X2WIJYPBREJSJ5JXNWKLFLKO\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: 6DPUDONKJ2WUDUUOEO5S7T2J\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: 2V2RUAKCVGQTBI5SEP3VZD7O\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-7801950e254a>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data_{year}_with_bands_subclass_{subclass_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-7801950e254a>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mExport\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madded\u001b[0m \u001b[0mbands\u001b[0m \u001b[0mto\u001b[0m \u001b[0mGoogle\u001b[0m \u001b[0mDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mimage_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-7801950e254a>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mprocessed_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomposite_with_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Filter out None values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Set working directory\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data')\n","\n","# Load shapefiles\n","shp_2018 = gpd.read_file('clean_data_no_bands/land_cover_2018.shp')\n","shp_2019 = gpd.read_file('clean_data_no_bands/land_cover_2019.shp')\n","shp_2020 = gpd.read_file('clean_data_no_bands/land_cover_2020.shp')\n","shp_2023 = gpd.read_file('clean_data_no_bands/land_cover_2023.shp')\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","\n","            # Check if min and max are valid\n","            is_valid = min_val.lt(max_val)\n","\n","            normalized_band = ee.Image(ee.Algorithms.If(\n","                is_valid,\n","                band.subtract(min_val).divide(max_val.subtract(min_val)),\n","                band  # If normalization fails, return the original band\n","            )).rename(ee.String(band_name).cat('_norm'))\n","\n","            return normalized_band\n","\n","        normalized_bands = ee.List(band_names).map(lambda band: normalize_band(ee.String(band)))\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size()\n","\n","            def process_collection(count):\n","                normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","                ndvi_collection = normalized_collection.map(self.calculate_ndvi)\n","\n","                print(f\"Number of images: {count.getInfo()}\")\n","\n","                bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","                composite = ndvi_collection.median().select(bands)\n","\n","                # Add a date band to the composite\n","                date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","                return composite.addBands(date_band)\n","\n","            composite_with_date = ee.Algorithms.If(\n","                count.gt(0),\n","                process_collection(count),\n","                None\n","            )\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        # Filter out None values\n","        processed_images = [img for img in processed_images if img is not None]\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed for any date range\")\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","            except ValueError as e:\n","                print(f\"No data available for {year}, subclass {subclass_name}: {str(e)}\")\n","            except Exception as e:\n","                print(f\"Unexpected error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10, 20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1251194,"status":"error","timestamp":1721576444348,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"NRsdw-VV2SiJ","outputId":"4aa92fc6-14a0-435c-e070-020834b5b299"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: ZTXZZPKI6SYLKQEXFI7UMMLG\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 6RX65HSTQSKIIUU4RRP5PTRK\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: NDS3KB7LGD74ZKFREMM3ZMQ3\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: 34AAAA7CUETAXO55EVIGW7E6\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-06-01 to 2018-08-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-09-30\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-10-31\n","Number of images: 1\n","Processing period: 2018-06-01 to 2018-11-30\n","Number of images: 1\n","Started export task: XN7LQ6ESFGWCRYYDNX5YJQQZ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: GMH2CRS5J5K345OKFEVHFGYO\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: FVM2ZDY4MAK7BY7UOUMKG5G3\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: OFOOWVRLGCENHOTTEODWUUYC\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-06-01 to 2019-08-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-09-30\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-10-31\n","Number of images: 1\n","Processing period: 2019-06-01 to 2019-11-30\n","Number of images: 1\n","Started export task: RV5VW463VDL2GRDTH43QMWEE\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: CJOPGTAB5KIGJIILVNA56JGJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: K5XANN4DICSW2P2PQAL7XD2T\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: 5TEEQC2WNOPNYDK5QWNQRX7A\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: RIUYYZQIBSM4TMBR7U62A5X2\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: YZJH6RE2OYL6NVDT47UTWWZA\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: JSSQ2CHKAJ6D7YC4CMVRWBVI\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n","Started export task: MLW5B76PMXQ32DNX47OHZ3M2\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-08-01 to 2020-08-31\n","Number of images: 0\n","Processing period: 2020-09-01 to 2020-09-30\n","Number of images: 1\n","Processing period: 2020-10-01 to 2020-10-31\n","Number of images: 1\n","Processing period: 2020-11-01 to 2020-11-30\n","Number of images: 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-8a97c4097960>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data_{year}_with_bands_subclass_{subclass_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-8a97c4097960>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mExport\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madded\u001b[0m \u001b[0mbands\u001b[0m \u001b[0mto\u001b[0m \u001b[0mGoogle\u001b[0m \u001b[0mDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mimage_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-8a97c4097960>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mprocessed_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomposite_with_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Set working directory\n","os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data')\n","\n","# Load shapefiles\n","shp_2018 = gpd.read_file('clean_data_no_bands/land_cover_2018.shp')\n","shp_2019 = gpd.read_file('clean_data_no_bands/land_cover_2019.shp')\n","shp_2020 = gpd.read_file('clean_data_no_bands/land_cover_2020.shp')\n","shp_2023 = gpd.read_file('clean_data_no_bands/land_cover_2023.shp')\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","            return normalized_band\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\") \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date)) \\\n","                .map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry())) \\\n","                .map(self.calculate_ndvi)\n","\n","            print(f\"Number of images: {nicfi_planet.size().getInfo()}\")\n","\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            composite = nicfi_planet.median().select(bands)\n","           # print(composite.getInfo())\n","\n","            # Add a date band to the composite\n","            date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","            composite_with_date = composite.addBands(date_band)\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(5, 10))\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=4.77,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands_planet_ncifi'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [ 2018, 2019,2020, 2023]#[\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-06-01', '2018-08-31'),\n","            ('2018-06-01', '2018-09-30'),\n","            ('2018-06-01', '2018-10-31'),\n","            ('2018-06-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-06-01', '2019-08-31'),\n","            ('2019-06-01', '2019-09-30'),\n","            ('2019-06-01', '2019-10-31'),\n","            ('2019-06-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    shp_data = {\n","        2018: shp_2018,\n","       2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(10,20))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"elapsed":60035,"status":"error","timestamp":1721569313798,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"WGVixF3GXU7a","outputId":"dd52753a-9134-4c8a-cd11-03874da7a7ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-08-01 to 2018-08-31\n","Number of images: {'type': 'ImageCollection', 'bands': [], 'version': 1721366263582886, 'id': 'projects/planet-nicfi/assets/basemaps/africa', 'properties': {'area': 'Tropical Africa ', 'system:time_start': 1598918400000, 'spectral_resolution': 'R,G,B,NIR', 'system:time_end': 1601424000000, 'description': 'This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use. To gain access you must sign the agreement available here: https://www.planet.com/nicfi/\\n\\n\\nIn support of NICFIs mission, you can use this data for a number of projects including, but not limited to:\\n\\n\\n\\xa0- Advance scientific research about the worlds tropical forests and the critical services they provide.\\n- Implement and improve policies for sustainable forest management and land use in developing tropical forest countries and jurisdictions.\\xa0\\n- Increase transparency and accountability in the tropics.\\n- Protect and improve the rights of indigenous peoples and local communities in tropical forest countries.\\xa0\\n- Innovate solutions towards reducing pressure on forests from global commodities and financial markets.\\n\\n\\nFull details about the Basemaps are available in [Planets NICFI Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf)\\xa0 For more information about NICFI and the NICFI Basemaps, see the FAQ [here](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).\\xa0', 'title': 'Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Africa', 'temporal_resolution': ' Archive (Dec 2015- Aug 2020, Bi-annual), Monitoring (Sept 2020- onwards, Monthly)', 'cadence': 'monthly', 'spatial_resolution': '4.77m per pixel'}, 'features': []}\n","Started export task: HZO4C5XYLSAZBLQEXCH5G7Y7\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-08-01 to 2018-08-31\n","Number of images: {'type': 'ImageCollection', 'bands': [], 'version': 1721366263582886, 'id': 'projects/planet-nicfi/assets/basemaps/africa', 'properties': {'area': 'Tropical Africa ', 'system:time_start': 1598918400000, 'spectral_resolution': 'R,G,B,NIR', 'system:time_end': 1601424000000, 'description': 'This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use. To gain access you must sign the agreement available here: https://www.planet.com/nicfi/\\n\\n\\nIn support of NICFIs mission, you can use this data for a number of projects including, but not limited to:\\n\\n\\n\\xa0- Advance scientific research about the worlds tropical forests and the critical services they provide.\\n- Implement and improve policies for sustainable forest management and land use in developing tropical forest countries and jurisdictions.\\xa0\\n- Increase transparency and accountability in the tropics.\\n- Protect and improve the rights of indigenous peoples and local communities in tropical forest countries.\\xa0\\n- Innovate solutions towards reducing pressure on forests from global commodities and financial markets.\\n\\n\\nFull details about the Basemaps are available in [Planets NICFI Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf)\\xa0 For more information about NICFI and the NICFI Basemaps, see the FAQ [here](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).\\xa0', 'title': 'Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Africa', 'temporal_resolution': ' Archive (Dec 2015- Aug 2020, Bi-annual), Monitoring (Sept 2020- onwards, Monthly)', 'cadence': 'monthly', 'spatial_resolution': '4.77m per pixel'}, 'features': []}\n","Started export task: WFG2NGZQLNNHURUYSZDRU335\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-08-01 to 2018-08-31\n","Number of images: {'type': 'ImageCollection', 'bands': [], 'version': 1721366263582886, 'id': 'projects/planet-nicfi/assets/basemaps/africa', 'properties': {'area': 'Tropical Africa ', 'system:time_start': 1598918400000, 'spectral_resolution': 'R,G,B,NIR', 'system:time_end': 1601424000000, 'description': 'This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use. To gain access you must sign the agreement available here: https://www.planet.com/nicfi/\\n\\n\\nIn support of NICFIs mission, you can use this data for a number of projects including, but not limited to:\\n\\n\\n\\xa0- Advance scientific research about the worlds tropical forests and the critical services they provide.\\n- Implement and improve policies for sustainable forest management and land use in developing tropical forest countries and jurisdictions.\\xa0\\n- Increase transparency and accountability in the tropics.\\n- Protect and improve the rights of indigenous peoples and local communities in tropical forest countries.\\xa0\\n- Innovate solutions towards reducing pressure on forests from global commodities and financial markets.\\n\\n\\nFull details about the Basemaps are available in [Planets NICFI Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf)\\xa0 For more information about NICFI and the NICFI Basemaps, see the FAQ [here](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).\\xa0', 'title': 'Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Africa', 'temporal_resolution': ' Archive (Dec 2015- Aug 2020, Bi-annual), Monitoring (Sept 2020- onwards, Monthly)', 'cadence': 'monthly', 'spatial_resolution': '4.77m per pixel'}, 'features': []}\n","Started export task: YMAAB67VBSVTVVDYE6KJ5QFQ\n","Check your Earth Engine Tasks panel to monitor progress.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-81be76115166>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# Add a delay between processing subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=4.77,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","            return normalized_band\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet =ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/africa\")\\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filter(ee.Filter.date(start_date, end_date)) \\\n","                .map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry())) \\\n","                .map(self.calculate_ndvi)\n","\n","            print(f\"Number of images: {nicfi_planet.getInfo()}\")\n","\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            composite = nicfi_planet.median().select(bands)\n","\n","            # Add a date band to the composite\n","            date_band = ee.Image.constant(ee.Date(start_date).millis()).rename('date')\n","            composite_with_date = composite.addBands(date_band)\n","\n","            processed_images.append(composite_with_date)\n","\n","            time.sleep(random.uniform(1, 3))\n","\n","        return ee.ImageCollection(processed_images)\n","\n","    def add_bands_to_fc(self, image_collection):\n","        \"\"\"\n","        Add the calculated bands to the feature collection as time series.\n","        \"\"\"\n","        def sample_image_collection(feature):\n","            values = image_collection.map(lambda image: image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )).toList(image_collection.size())\n","\n","            return feature.set('time_series', values)\n","\n","        return self.data_fc.map(sample_image_collection)\n","\n","    def export_to_drive(self, description, file_format='CSV', folder='clean_data_with_bands'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        image_collection = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(image_collection)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-08-01', '2018-08-31'),\n","            # ('2018-09-01', '2018-09-30'),\n","            # ('2018-10-01', '2018-10-31'),\n","            # ('2018-11-01', '2018-11-30')\n","        ],\n","        # 2019: [\n","        #     ('2019-08-01', '2019-08-31'),\n","        #     ('2019-09-01', '2019-09-30'),\n","        #     ('2019-10-01', '2019-10-31'),\n","        #     ('2019-11-01', '2019-11-30')\n","        # ],\n","        # 2020: [\n","        #     ('2020-08-01', '2020-08-31'),\n","        #     ('2020-09-01', '2020-09-30'),\n","        #     ('2020-10-01', '2020-10-31'),\n","        #     ('2020-11-01', '2020-11-30')\n","        # ],\n","        # 2023: [\n","        #     ('2023-08-01', '2023-08-31'),\n","        #     ('2023-09-01', '2023-09-30'),\n","        #     ('2023-10-01', '2023-10-31'),\n","        #     ('2023-11-01', '2023-11-30')\n","        # ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","       # 2019: shp_2019,\n","       # 2020: shp_2020,\n","       # 2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwTK4_xhJ6UC"},"outputs":[],"source":["\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, months, indices, data_fc):\n","        self.year = year\n","        self.months = months\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","            #print(f\"Normalized {band_name} with min: {min_val.getInfo()}, max: {max_val.getInfo()}\")\n","            return normalized_band\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified months.\n","        \"\"\"\n","\n","        for month_index, month in enumerate(self.months):\n","            start_date = ee.Date.fromYMD(self.year, month, 1)\n","            end_date = ee.Date.fromYMD(self.year, ee.Number(month).add(1), 1)\n","            print(start_date.getInfo(), end_date.getInfo())\n","            # Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","            nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filterDate(start_date, end_date)\\\n","                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) \\\n","                .map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry())) \\\n","                .map(self.calculate_ndvi)\n","\n","            # Select bands to use for classification\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            # Reduce the image collection to median to get a single composite image\n","            composite = nicfi_planet.median().select(bands)\n","           #processed_images.append(composite)\n","\n","            # Add a delay between processing months\n","            time.sleep(random.uniform(1, 3))\n","        return composite\n","\n","\n","    def retry_function(self, func, max_retries=5, initial_delay=1, factor=2):\n","        \"\"\"\n","        Retry a function with exponential backoff in case of rate limit errors.\n","        \"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        \"\"\"\n","        Add the calculated bands to the feature collection.\n","        \"\"\"\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='clean_data_with_bands'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        combined_image = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, months, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, months, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":1525,"status":"error","timestamp":1721565549483,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"-Ltn_Y8y7vyA","outputId":"4f454a5b-51c2-48db-dad2-098ffa9808d1"},"outputs":[{"ename":"TypeError","evalue":"not all arguments converted during string formatting","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-9b46df6184fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubclassProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_ranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data_{year}_with_bands_subclass_{subclass_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-4670782d0bb3>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mExport\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madded\u001b[0m \u001b[0mbands\u001b[0m \u001b[0mto\u001b[0m \u001b[0mGoogle\u001b[0m \u001b[0mDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mcombined_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-4670782d0bb3>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmonth_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromYMD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromYMD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/ee_date.py\u001b[0m in \u001b[0;36mfromYMD\u001b[0;34m(year, month, day, timeZone)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \"\"\"\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     return apifunction.ApiFunction.call_(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;34m'Date.fromYMD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeZone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/apifunction.py\u001b[0m in \u001b[0;36mcall_\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0ma\u001b[0m \u001b[0mrecognized\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnameArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, named_args)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputedobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputedObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpromoteArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_promoter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetReturnType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/function.py\u001b[0m in \u001b[0;36mpromoteArgs\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mpromoted_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_promoter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         raise ee_exception.EEException(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/__init__.py\u001b[0m in \u001b[0;36m_Promote\u001b[0;34m(arg, a_class)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0ma_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Long'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Short'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Byte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0ma_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/ee_number.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       raise ee_exception.EEException(\n\u001b[0;32m---> 48\u001b[0;31m           'Invalid argument specified for ee.Number(): %s' % number)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"]}],"source":["if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-08-01', '2018-08-31'),\n","            ('2018-09-01', '2018-09-30'),\n","            ('2018-10-01', '2018-10-31'),\n","            ('2018-11-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-08-01', '2019-08-31'),\n","            ('2019-09-01', '2019-09-30'),\n","            ('2019-10-01', '2019-10-31'),\n","            ('2019-11-01', '2019-11-30')\n","        ],\n","        # Add ranges for 2020 and 2023\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        #2020: shp_2020,\n","        #2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                processor.export_to_drive(f'data_{year}_with_bands_subclass_{subclass_name}')\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":664},"executionInfo":{"elapsed":125405,"status":"error","timestamp":1721566218694,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"S5PEmVQr8T_7","outputId":"0c8d4643-6d8d-451f-ec4c-5eb8114c3ff4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","Error processing 2018, subclass cereals: Image.select: Band pattern 'B_norm' was applied to an Image with no bands. See https://developers.google.com/earth-engine/guides/debugging#no-bands\n","Processing period: 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","Error processing 2018, subclass legumes: Image.select: Band pattern 'B_norm' was applied to an Image with no bands. See https://developers.google.com/earth-engine/guides/debugging#no-bands\n","Processing period: 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","Error processing 2018, subclass noncrop: Image.select: Band pattern 'B_norm' was applied to an Image with no bands. See https://developers.google.com/earth-engine/guides/debugging#no-bands\n","Processing period: 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","Error processing 2018, subclass tree_crops: Image.select: Band pattern 'B_norm' was applied to an Image with no bands. See https://developers.google.com/earth-engine/guides/debugging#no-bands\n","Processing period: 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","Error processing 2018, subclass vegetables: Image.select: Band pattern 'B_norm' was applied to an Image with no bands. See https://developers.google.com/earth-engine/guides/debugging#no-bands\n"]},{"ename":"KeyError","evalue":"2019","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-8a0464ed04f9>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Process each year and each subclass separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass_df\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sub_class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubclassProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_ranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 2019"]}],"source":["class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges  # List of tuples (start_date, end_date)\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        \"\"\"\n","        Calculate the NDVI for an image and add it as a band.\n","        \"\"\"\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        \"\"\"\n","        Normalize the specified bands of an image.\n","        \"\"\"\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","            return normalized_band\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        \"\"\"\n","        Process the NICFI Planet imagery for all specified date ranges.\n","        \"\"\"\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filterDate(start_date, end_date) \\\n","                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) \\\n","                .map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry())) \\\n","                .map(self.calculate_ndvi)\n","\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            composite = nicfi_planet.median().select(bands)\n","            processed_images.append(composite)\n","\n","            time.sleep(random.uniform(1, 3))\n","\n","        return ee.Image.cat(processed_images)\n","\n","    def retry_function(self, func, max_retries=5, initial_delay=1, factor=2):\n","        \"\"\"\n","        Retry a function with exponential backoff in case of rate limit errors.\n","        \"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        \"\"\"\n","        Add the calculated bands to the feature collection.\n","        \"\"\"\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='clean_data_with_bands'):\n","        \"\"\"\n","        Export the feature collection with added bands to Google Drive.\n","        \"\"\"\n","        combined_image = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","        print(data_with_bands.getInfo())\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    \"\"\"\n","    Convert a GeoDataFrame to an Earth Engine Feature Collection.\n","    \"\"\"\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = [list(polygon.exterior.coords) for polygon in geometry.geoms]\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-08-01', '2018-08-31'),\n","            ('2018-09-01', '2018-09-30'),\n","            ('2018-10-01', '2018-10-31'),\n","            ('2018-11-01', '2018-11-30')\n","         ],\n","        # 2019: [\n","        #     ('2019-08-01', '2019-08-31'),\n","        #     ('2019-09-01', '2019-09-30'),\n","        #     ('2019-10-01', '2019-10-31'),\n","        #     ('2019-11-01', '2019-11-30')\n","        # ],\n","        # 2020: [\n","        #     ('2020-08-01', '2020-08-31'),\n","        #     ('2020-09-01', '2020-09-30'),\n","        #     ('2020-10-01', '2020-10-31'),\n","        #     ('2020-11-01', '2020-11-30')\n","        # ],\n","        # 2023: [\n","        #     ('2023-08-01', '2023-08-31'),\n","        #     ('2023-09-01', '2023-09-30'),\n","        #     ('2023-10-01', '2023-10-31'),\n","        #     ('2023-11-01', '2023-11-30')\n","        # ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        #2019: shp_2019,\n","       # 2020: shp_2020,\n","        #2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":1408,"status":"error","timestamp":1721526892905,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"8slHTc3brP0F","outputId":"4056dd6f-a3eb-488d-ea3c-bc6f183d3085"},"outputs":[{"ename":"AttributeError","evalue":"'SubclassProcessor' object has no attribute 'date_ranges'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-6ac28ed0395a>\u001b[0m in \u001b[0;36m<cell line: 154>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data_{year}_with_bands_subclass_{subclass_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-6ac28ed0395a>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data_with_bands_planet_ncifi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mcombined_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-6ac28ed0395a>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprocessed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_ranges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing period: {start_date} to {end_date}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SubclassProcessor' object has no attribute 'date_ranges'"]}],"source":["class PlanetNICFIProcessor:\n","    def __init__(self, year, months, indices, data_fc):\n","        self.year = year\n","        self.months = months\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            return band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","\n","      processed_images = []\n","\n","      for start_date, end_date in self.date_ranges:\n","          print(f\"Processing period: {start_date} to {end_date}\")\n","\n","          nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","              .filterBounds(self.data_fc.geometry()) \\\n","              .filterDate(start_date, end_date) \\\n","              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n","\n","          # Check if the collection is empty\n","          count = nicfi_planet.size().getInfo()\n","          if count == 0:\n","              print(f\"No images found for the period {start_date} to {end_date}\")\n","              continue\n","\n","          # Print the bands of the first image\n","          first_image = ee.Image(nicfi_planet.first())\n","          print(f\"Bands in the original image: {first_image.bandNames().getInfo()}\")\n","\n","          normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","\n","          # Check the bands after normalization\n","          first_normalized = ee.Image(normalized_collection.first())\n","          print(f\"Bands after normalization: {first_normalized.bandNames().getInfo()}\")\n","\n","          with_ndvi = normalized_collection.map(self.calculate_ndvi)\n","\n","          bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","          composite = with_ndvi.median()\n","\n","          # Check if all required bands are present\n","          available_bands = composite.bandNames().getInfo()\n","          missing_bands = [band for band in bands if band not in available_bands]\n","          if missing_bands:\n","              print(f\"Warning: The following bands are missing: {missing_bands}\")\n","              # Only select available bands\n","              bands = [band for band in bands if band in available_bands]\n","\n","          if not bands:\n","              print(\"Error: No required bands are available in the composite image\")\n","              continue\n","\n","          composite = composite.select(bands)\n","          processed_images.append(composite)\n","\n","          time.sleep(random.uniform(1, 3))\n","\n","      if not processed_images:\n","          raise ValueError(\"No images were processed successfully\")\n","\n","      return ee.Image.cat(processed_images)\n","\n","    def retry_function(self, func, max_retries=5, initial_delay=1, factor=2):\n","        \"\"\"Retry a function with exponential backoff.\"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='data_with_bands_planet_ncifi'):\n","        combined_image = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = []\n","            for polygon in geometry.geoms:\n","                polygons.append(list(polygon.exterior.coords))\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-08-01', '2018-08-31'),\n","            ('2018-09-01', '2018-09-30'),\n","            ('2018-10-01', '2018-10-31'),\n","            ('2018-11-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-08-01', '2019-08-31'),\n","            ('2019-09-01', '2019-09-30'),\n","            ('2019-10-01', '2019-10-31'),\n","            ('2019-11-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"executionInfo":{"elapsed":16496,"status":"error","timestamp":1721527163485,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"JL1TIEtlAflv","outputId":"5607eeb4-7e50-4f87-8f8f-eaf691e59079"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-08-01 to 2018-08-31\n","No images found for the period 2018-08-01 to 2018-08-31\n","Processing period: 2018-09-01 to 2018-09-30\n","No images found for the period 2018-09-01 to 2018-09-30\n","Processing period: 2018-10-01 to 2018-10-31\n","No images found for the period 2018-10-01 to 2018-10-31\n","Processing period: 2018-11-01 to 2018-11-30\n","No images found for the period 2018-11-01 to 2018-11-30\n"]},{"ename":"ValueError","evalue":"No images were processed successfully","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-07c8c59dd6d2>\u001b[0m in \u001b[0;36m<cell line: 170>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"data_{year}_with_bands_subclass_{subclass_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {year}, subclass {subclass_name}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-07c8c59dd6d2>\u001b[0m in \u001b[0;36mexport_to_drive\u001b[0;34m(self, description, file_format, folder)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data_with_bands_planet_ncifi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mcombined_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_months\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mdata_with_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bands_to_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-07c8c59dd6d2>\u001b[0m in \u001b[0;36mprocess_all_months\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprocessed_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No images were processed successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No images were processed successfully"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Jul 19 23:39:24 2024\n","\n","@author: Janet.Mutuku\n","\n","This script processes land cover data for various years using Google Earth Engine (GEE) and outputs the results as shapefiles.\n","\"\"\"\n","\n","import ee\n","import time\n","import random\n","import os\n","from shapely.geometry import Polygon, MultiPolygon\n","\n","# Initialize Earth Engine\n","ee.Initialize()\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            return band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        processed_images = []\n","\n","        for start_date, end_date in self.date_ranges:\n","            print(f\"Processing period: {start_date} to {end_date}\")\n","\n","            nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","                .filterBounds(self.data_fc.geometry()) \\\n","                .filterDate(start_date, end_date) \\\n","                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n","\n","            # Check if the collection is empty\n","            count = nicfi_planet.size().getInfo()\n","            if count == 0:\n","                print(f\"No images found for the period {start_date} to {end_date}\")\n","                continue\n","\n","            # Print the bands of the first image\n","            first_image = ee.Image(nicfi_planet.first())\n","            print(f\"Bands in the original image: {first_image.bandNames().getInfo()}\")\n","\n","            normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","\n","            # Check the bands after normalization\n","            first_normalized = ee.Image(normalized_collection.first())\n","            print(f\"Bands after normalization: {first_normalized.bandNames().getInfo()}\")\n","\n","            with_ndvi = normalized_collection.map(self.calculate_ndvi)\n","\n","            bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","            composite = with_ndvi.median()\n","\n","            # Check if all required bands are present\n","            available_bands = composite.bandNames().getInfo()\n","            missing_bands = [band for band in bands if band not in available_bands]\n","            if missing_bands:\n","                print(f\"Warning: The following bands are missing: {missing_bands}\")\n","                # Only select available bands\n","                bands = [band for band in bands if band in available_bands]\n","\n","            if not bands:\n","                print(\"Error: No required bands are available in the composite image\")\n","                continue\n","\n","            composite = composite.select(bands)\n","            processed_images.append(composite)\n","\n","            time.sleep(random.uniform(1, 3))\n","\n","        if not processed_images:\n","            raise ValueError(\"No images were processed successfully\")\n","\n","        return ee.Image.cat(processed_images)\n","\n","    def retry_function(self, func, max_retries=5, initial_delay=1, factor=2):\n","        \"\"\"Retry a function with exponential backoff.\"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='data_with_bands_planet_ncifi'):\n","        combined_image = self.process_all_months()\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = []\n","            for polygon in geometry.geoms:\n","                polygons.append(list(polygon.exterior.coords))\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year\n","    date_ranges = {\n","        2018: [\n","            ('2018-08-01', '2018-08-31'),\n","            ('2018-09-01', '2018-09-30'),\n","            ('2018-10-01', '2018-10-31'),\n","            ('2018-11-01', '2018-11-30')\n","        ],\n","        2019: [\n","            ('2019-08-01', '2019-08-31'),\n","            ('2019-09-01', '2019-09-30'),\n","            ('2019-10-01', '2019-10-31'),\n","            ('2019-11-01', '2019-11-30')\n","        ],\n","        2020: [\n","            ('2020-08-01', '2020-08-31'),\n","            ('2020-09-01', '2020-09-30'),\n","            ('2020-10-01', '2020-10-31'),\n","            ('2020-11-01', '2020-11-30')\n","        ],\n","        2023: [\n","            ('2023-08-01', '2023-08-31'),\n","            ('2023-09-01', '2023-09-30'),\n","            ('2023-10-01', '2023-10-31'),\n","            ('2023-11-01', '2023-11-30')\n","        ]\n","    }\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5262589,"status":"ok","timestamp":1721533760127,"user":{"displayName":"Janet Mumo MUTUKU","userId":"08778445167667830809"},"user_tz":0},"id":"Vg6uu59ABvrW","outputId":"680a530d-a939-4172-a37b-2c610ea9a963"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing period: 2018-01-01 to 2018-12-31\n","Found 2 images for the year 2018\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: UBWQDZP4UJ7WOGSDQD7EK2TJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-01-01 to 2018-12-31\n","Found 2 images for the year 2018\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: XFY3J5XSXT2PUV5MBBBTQF62\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-01-01 to 2018-12-31\n","Found 2 images for the year 2018\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: NN4SDJU7YPFYOFW7KC5R4ECU\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-01-01 to 2018-12-31\n","Found 2 images for the year 2018\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: TCFEPFGQGEYLB3SDKOWF6OQJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2018-01-01 to 2018-12-31\n","Found 2 images for the year 2018\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: STQLUIRBMNIENFCHIRBSVYZN\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-01-01 to 2019-12-31\n","Found 2 images for the year 2019\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: PXOUUI2NGUCDATBWQMU27ET3\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-01-01 to 2019-12-31\n","Found 2 images for the year 2019\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: M26UPLSIK3QXY6TDHYQNQ5PJ\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-01-01 to 2019-12-31\n","Found 2 images for the year 2019\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: 7IFMECJEKJKNGWTIXNZ7HOPI\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2019-01-01 to 2019-12-31\n","Found 2 images for the year 2019\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: U2XVCTL7QFFQ6POKBCVMEGPS\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.04 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.09 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 6.52 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.70 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 17.25 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass bare_built_up: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.18 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 503\n","WARNING:googleapiclient.http:Sleeping 2.25 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 503\n","WARNING:googleapiclient.http:Sleeping 5.92 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 503\n","WARNING:googleapiclient.http:Sleeping 9.20 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 503\n","WARNING:googleapiclient.http:Sleeping 28.99 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 503\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass cereals: The service is currently unavailable.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.05 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 0.39 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 5.74 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 3.51 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 31.11 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass fallow: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.64 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 3.19 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.54 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 4.60 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 12.26 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass legumes: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.98 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 0.13 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 7.25 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 0.55 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 10.02 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass noncrop: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.75 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.55 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 6.96 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 10.18 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 7.65 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass other_vegetation: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.82 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.49 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.42 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 0.77 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 23.46 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass tree_crops: Too many concurrent aggregations.\n","Processing period: 2020-01-01 to 2020-12-31\n","Found 5 images for the year 2020\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.42 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.79 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 5.24 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 4.31 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 8.83 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2020, subclass vegetables: Too many concurrent aggregations.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.82 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.36 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 6.60 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 7.47 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 9.78 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2023, subclass cereals: Too many concurrent aggregations.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.68 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 3.96 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.63 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.09 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 29.77 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2023, subclass fallow: Too many concurrent aggregations.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.46 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 2.73 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.05 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 9.16 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 5.77 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2023, subclass legumes: Too many concurrent aggregations.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n","Bands after normalization: ['B', 'G', 'R', 'N', 'NDVI', 'B_norm', 'G_norm', 'R_norm', 'N_norm']\n","Started export task: XXUGTHSQ67HUTXU4RWOA3NPH\n","Check your Earth Engine Tasks panel to monitor progress.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 1.48 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 3.84 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.95 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 8.51 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 7.90 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2023, subclass tree_crops: Too many concurrent aggregations.\n","Processing period: 2023-01-01 to 2023-12-31\n","Found 12 images for the year 2023\n","Bands in the original image: ['B', 'G', 'R', 'N', 'NDVI']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:googleapiclient.http:Sleeping 0.28 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 0.90 seconds before retry 2 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 4.83 seconds before retry 3 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 1.93 seconds before retry 4 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n","WARNING:googleapiclient.http:Sleeping 5.81 seconds before retry 5 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-janet/value:compute?prettyPrint=false&alt=json, after 429\n"]},{"name":"stdout","output_type":"stream","text":["Error processing 2023, subclass vegetables: Too many concurrent aggregations.\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Jul 19 23:39:24 2024\n","\n","@author: Janet.Mutuku\n","\n","This script processes land cover data for various years using Google Earth Engine (GEE) and outputs the results as shapefiles.\n","\"\"\"\n","\n","import ee\n","import time\n","import random\n","import os\n","from shapely.geometry import Polygon, MultiPolygon\n","\n","# Initialize Earth Engine\n","ee.Initialize()\n","\n","class PlanetNICFIProcessor:\n","    def __init__(self, year, date_ranges, indices, data_fc):\n","        self.year = year\n","        self.date_ranges = date_ranges\n","        self.indices = indices\n","        self.data_fc = data_fc\n","\n","    def calculate_ndvi(self, image):\n","        return image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI'))\n","\n","    def normalize_bands(self, image, band_names, geometry):\n","        def normalize_band(band_name):\n","            band = image.select(band_name).toFloat()\n","            min_max = band.reduceRegion(\n","                reducer=ee.Reducer.minMax(),\n","                geometry=geometry,\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            min_val = ee.Number(min_max.get(ee.String(band_name).cat('_min')))\n","            max_val = ee.Number(min_max.get(ee.String(band_name).cat('_max')))\n","            return band.subtract(min_val).divide(max_val.subtract(min_val)).rename(ee.String(band_name).cat('_norm'))\n","\n","        normalized_bands = [normalize_band(band) for band in band_names]\n","        return image.addBands(ee.Image.cat(normalized_bands))\n","\n","    def process_all_months(self):\n","        processed_images = []\n","\n","        # Use the entire year instead of specific months\n","        start_date = f\"{self.year}-01-01\"\n","        end_date = f\"{self.year}-12-31\"\n","        print(f\"Processing period: {start_date} to {end_date}\")\n","\n","        nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","            .filterBounds(self.data_fc.geometry()) \\\n","            .filterDate(start_date, end_date) \\\n","            .map(self.calculate_ndvi)\n","\n","        # Check if the collection is empty\n","        count = nicfi_planet.size().getInfo()\n","        if count == 0:\n","            print(f\"No images found for the year {self.year}\")\n","            print(f\"Geometry bounds: {self.data_fc.geometry().bounds().getInfo()}\")\n","            return None\n","\n","        print(f\"Found {count} images for the year {self.year}\")\n","\n","        # Print the bands of the first image\n","        first_image = ee.Image(nicfi_planet.first())\n","        print(f\"Bands in the original image: {first_image.bandNames().getInfo()}\")\n","\n","        normalized_collection = nicfi_planet.map(lambda image: self.normalize_bands(image, ['B', 'G', 'R', 'N'], self.data_fc.geometry()))\n","\n","        # Check the bands after normalization\n","        first_normalized = ee.Image(normalized_collection.median())\n","        print(f\"Bands after normalization: {first_normalized.bandNames().getInfo()}\")\n","\n","        with_ndvi = normalized_collection#.map(self.calculate_ndvi)\n","\n","        bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","        composite = with_ndvi.median().select(bands)\n","\n","        # Check if all required bands are present\n","        available_bands = composite.bandNames().getInfo()\n","        missing_bands = [band for band in bands if band not in available_bands]\n","        if missing_bands:\n","            print(f\"Warning: The following bands are missing: {missing_bands}\")\n","            # Only select available bands\n","            bands = [band for band in bands if band in available_bands]\n","\n","        if not bands:\n","            print(\"Error: No required bands are available in the composite image\")\n","            return None\n","\n","        processed_images.append(composite)\n","\n","        if not processed_images:\n","            print(\"No images were processed successfully\")\n","            return None\n","\n","        return ee.Image.cat(processed_images)\n","\n","    def retry_function(self, func, max_retries=5, initial_delay=1, factor=2):\n","        \"\"\"Retry a function with exponential backoff.\"\"\"\n","        retries = 0\n","        while retries < max_retries:\n","            try:\n","                return func()\n","            except ee.ee_exception.EEException as e:\n","                if \"Too many concurrent aggregations\" in str(e):\n","                    retries += 1\n","                    if retries == max_retries:\n","                        raise\n","                    delay = initial_delay * (factor ** retries) + random.uniform(0, 1)\n","                    print(f\"Rate limit hit. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                else:\n","                    raise\n","\n","    def add_bands_to_fc(self, image):\n","        def sample_image(feature):\n","            values = image.reduceRegion(\n","                reducer=ee.Reducer.mean(),\n","                geometry=feature.geometry(),\n","                scale=5,\n","                maxPixels=1e13\n","            )\n","            return feature.set(values)\n","\n","        return self.data_fc.map(sample_image)\n","\n","    def export_to_drive(self, description, file_format='SHP', folder='data_with_bands_planet_ncifi'):\n","        combined_image = self.process_all_months()\n","        if combined_image is None:\n","            print(f\"No data to export for {description}\")\n","            return\n","\n","        data_with_bands = self.add_bands_to_fc(combined_image)\n","\n","        task = ee.batch.Export.table.toDrive(\n","            collection=data_with_bands,\n","            description=description,\n","            fileFormat=file_format,\n","            folder=folder\n","        )\n","        task.start()\n","        print(f\"Started export task: {task.id}\")\n","        print(\"Check your Earth Engine Tasks panel to monitor progress.\")\n","\n","class SubclassProcessor(PlanetNICFIProcessor):\n","    def __init__(self, subclass_df, year, date_ranges, indices, subclass_name):\n","        data_fc = gdf_to_ee_feature_collection(subclass_df)\n","        super().__init__(year, date_ranges, indices, data_fc)\n","        self.subclass_name = subclass_name\n","\n","def gdf_to_ee_feature_collection(gdf):\n","    features = []\n","    for i, row in gdf.iterrows():\n","        geometry = row.geometry\n","        if isinstance(geometry, Polygon):\n","            ee_geometry = ee.Geometry.Polygon(list(geometry.exterior.coords))\n","        elif isinstance(geometry, MultiPolygon):\n","            polygons = []\n","            for polygon in geometry.geoms:\n","                polygons.append(list(polygon.exterior.coords))\n","            ee_geometry = ee.Geometry.MultiPolygon(polygons)\n","        else:\n","            raise TypeError(f\"Unsupported geometry type: {type(geometry)}\")\n","\n","        properties = row.drop('geometry').fillna(0).to_dict()  # Replace NaN with 0\n","        feature = ee.Feature(ee_geometry, properties)\n","        features.append(feature)\n","\n","    return ee.FeatureCollection(features)\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Set up your Google Drive folder\n","    os.chdir('/content/drive/MyDrive/Crop Monitoring/crop_monitoring/crop_types_data/data_with_bands_planet_ncifi')\n","\n","    # Years to process\n","    years = [2018, 2019, 2020, 2023]\n","\n","    # Define date ranges for each year (now using the entire year)\n","    date_ranges = {year: [(f\"{year}-01-01\", f\"{year}-12-31\")] for year in years}\n","\n","    indices = ['NDVI']  # Add more indices as you wish\n","\n","    # Assuming 'shp_data' is a dictionary with years as keys and GeoDataFrames as values\n","    # You need to define these GeoDataFrames (shp_2018, shp_2019, shp_2020, shp_2023) before this point\n","    shp_data = {\n","        2018: shp_2018,\n","        2019: shp_2019,\n","        2020: shp_2020,\n","        2023: shp_2023\n","    }\n","\n","    # Process each year and each subclass separately\n","    for year in years:\n","        for subclass_name, subclass_df in shp_data[year].groupby('Sub_class'):\n","            processor = SubclassProcessor(subclass_df, year, date_ranges[year], indices, subclass_name)\n","            try:\n","                # Ensure the description is a string and doesn't contain any special formatting characters\n","                description = f\"data_{year}_with_bands_subclass_{subclass_name}\"\n","                description = description.replace(\"%\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n","                processor.export_to_drive(description)\n","            except ee.ee_exception.EEException as e:\n","                print(f\"Error processing {year}, subclass {subclass_name}: {str(e)}\")\n","\n","            # Add a delay between processing subclasses\n","            time.sleep(random.uniform(5, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVDH9JieBgYJ"},"outputs":[],"source":["# Import necessary librari\n","from google.colab import drive\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load Sentinel-2 imagery and filter by date and bounds of the polygons\n","sentinel2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n","    .filterBounds(data_2020).filterDate('2020-09-01', '2020-09-28') \\\n","    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B2', 'B3', 'B4', 'B8', 'NDVI']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = sentinel2.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        sampled = image.reduceRegion(           #Reduce the image collection to get a median composite image.\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=10,\n","            maxPixels=1e13\n","        )\n","        return feature.set(sampled)   #Create a function to add bands to the feature collection by sampling the image.\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","data_2020_with_bands = add_bands_to_fc(data_2020, image)  # using teh cleaned data -- can change to the original data\n","\n","#Convert FeatureCollection to pandas DataFrame\n","def fc_to_df(fc):\n","    features = fc.getInfo()['features']\n","    dict_list = [f['properties'] for f in features]\n","    df = pd.DataFrame(dict_list)\n","    return df\n","\n","# Display the first 5 rows of the dataframe\n","df = fc_to_df(data_2020_with_bands)\n","print(df.head())\n","\n","# Export the new shapefile dataset to Google Drive\n","export_task = ee.batch.Export.table.toDrive(\n","    collection=data_2020_with_bands,\n","    description='data_2020_with_bands_sep',\n","    fileFormat='SHP'\n",")\n","\n","export_task.start()\n","\n","# Monitor the task status\n","while export_task.active():\n","    print('Polling for task (id: {}).'.format(export_task.id))\n","    time.sleep(30)\n","\n","print('Export task completed with status:', export_task.status())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DwlUQdrjQzI"},"outputs":[],"source":["# Function to get feature properties\n","def get_properties(feature):\n","    return ee.Feature(None, feature.toDictionary())\n","\n","# Map the function over the collection\n","properties_list = data_2018.map(get_properties).getInfo()\n","\n","# Extract properties from the list of features\n","properties_list = [feature['properties'] for feature in properties_list['features']]\n","\n","# Convert the list of dictionaries to a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Rename columns if needed\n","#df.rename(columns={'Annee': 'Year'}, inplace=True) #df.rename(columns={'old_column_name': 'new_column_name'}, inplace=True)\n","\n","\n","# Display the DataFrame\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwPMJy6wnhsi"},"outputs":[],"source":["# @title Crop_Ncrop\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","df.groupby('Crop_Ncrop').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n","plt.gca().spines[['top', 'right',]].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrCAC6fmm86c"},"outputs":[],"source":["# @title Average Area by Crop Type\n","\n","df.groupby('Speculatio')['Sup_ha'].mean().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZhvsQ1OmZgz"},"outputs":[],"source":["# @title Admin1\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","df.groupby('Admin1').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n","plt.gca().spines[['top', 'right',]].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp9dkcLqdtnM"},"outputs":[],"source":["# Check for NaN values in each column\n","nan_counts = df.isna().sum()\n","\n","# Display the columns with their respective NaN counts\n","print(nan_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mnaVCgZdd3tg"},"outputs":[],"source":["# Display only columns with NaN values\n","nan_columns = nan_counts[nan_counts > 0]\n","print(nan_columns)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDtRO5zDlYo9"},"outputs":[],"source":["# @title Default title text\n","# Define a function to add Earth Engine vector data as a layer to a Folium map\n","def add_ee_vector_layer(feature_collection, style, layer_name, map_object):\n","    painted = ee.Image().paint(feature_collection, 'constant', 2)  # Here 'constant' is a dummy property for visualization\n","    map_id_dict = painted.getMapId(style)\n","    folium.TileLayer(\n","        tiles=map_id_dict['tile_fetcher'].url_format,\n","        attr='Map Data &copy; Google Earth Engine',\n","        name=layer_name,\n","        overlay=True,\n","        control=True\n","    ).add_to(map_object)\n","\n","# Create a Folium map object\n","center = [14.4974, -14.4524]  # Center of the map (e.g., Senegal)\n","m1 = folium.Map(location=center, zoom_start=7)\n","\n","# Styling for the vector layer\n","style = {\n","    'color': 'blue',  # Line color\n","    'fillColor': '00000000',  # Fill color with opacity (00)\n","}\n","\n","# Add the merged crop fields to the map\n","add_ee_vector_layer(data_2018, style, 'Merged Crops 2019-2020', m1)\n","\n","# Add a layer control panel to the map\n","folium.LayerControl().add_to(m1)\n","\n","# Display the map\n","m1\n"]},{"cell_type":"markdown","metadata":{"id":"tVWi-cw_kcn7"},"source":["### Polygons for FY2023"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDb9ZbKaNjuv"},"outputs":[],"source":["print(vegetables.size().getInfo())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhTw6LAYN1Le"},"outputs":[],"source":["print(sorgh.size().getInfo())"]},{"cell_type":"markdown","metadata":{"id":"UEhnPNgHfEgp"},"source":["Next steps:\n","- create shape file with bands and NDVI\n","- edit the clumen class of crop, fallow, N-crop etc\n","- export the classes and bands in to Google earht engine asset\n","- and test the new asset if band values and added class are in GEE ASSET"]},{"cell_type":"markdown","metadata":{"id":"gVEDXrS3SAln"},"source":["### Normalized bands : integrate the bands in to shapfle (Vector) \n","\n","To normalize the spectral bands, we'll create a function that normalizes each band by subtracting the minimum value and dividing by the range (max - min) of that band. We'll apply this function to each band in the image collection before calculating the NDVI and proceeding with the rest of the steps."]},{"cell_type":"markdown","metadata":{"id":"Qg52fWhW4pyN"},"source":["### Senti2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQnOwlNjmZ9z"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load Sentinel-2 imagery and filter by date and bounds of the polygons\n","sentinel2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n","    .filterBounds(gnut.geometry()) \\\n","    .filterDate('2023-08-10', '2023-10-10') \\\n","    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n","    .map(lambda image: normalize_bands(image, ['B2', 'B3', 'B4', 'B8'], gnut.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B2_norm', 'B3_norm', 'B4_norm', 'B8_norm', 'NDVI', 'B2', 'B3', 'B4', 'B8']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = sentinel2.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        # Sample the image at the feature's geometry\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=10,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        # Convert the sampled dictionary to ensure all keys have non-null values\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Ensure that sampled values are added correctly to the feature\n","        return feature.set(sampled)\n","\n","    # Apply the add_bands function to each feature in the feature collection\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(gnut, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('class', 'crop').set('sub_class', 'legume').set('year', '2023').set('region', '???') #Annee = year, Sub-class = Type, Crop_Ncrop = class\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename the property \"Speculat\" to \"Speculatio\"\n","def rename_speculat_to_speculatio(feature):\n","    return rename_property(feature, 'Speculat', 'name') #name =Speculatio)\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_speculat_to_speculatio)\n","\n","# Get the first few features to display their properties\n","features_to_display = merged2023_class_with_properties.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", merged2023_class_with_properties.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=merged2023_class_with_properties,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/groundnut_class_final_x'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gqRhB4eAMCj"},"outputs":[],"source":["\n","#sub-classs\n","cereals2 = soye.merge(millet).merge(milletmix).merge(sorgh).merge(fonio).merge(maize).merge(millet).merge(sesame).merge(wheat).merge(rice) #class = crop, and sub_class = cereals\n","legumes = gnut.merge(gnutmix).merge(cowpea).merge(cowpmix).merge(vouandzou) #class = crop, and sub_class = legumes\n","vegetables = cassava.merge(eggplant).merge(gsorrel).merge(okra).merge(potato).merge(squash).merge(taro).merge(melon) #class = crop, and sub_class = vegetables\n","fallow #as class and sub-class\n","tree_crops = cashew #as class and sub-class\n","#fallow = fallow.filter(ee.Filter.eq('class', 'Fallow')) #.merge(fallow) is not a crop"]},{"cell_type":"markdown","metadata":{"id":"A4bpQc3r37eZ"},"source":["### NICFI"]},{"cell_type":"markdown","metadata":{"id":"Csiw3nd3wUAu"},"source":["### Export all Classes and Sub-Classes as one SHP with band+ classes _NICFI Data"]},{"cell_type":"markdown","metadata":{"id":"p-fusvboA-Rc"},"source":["Fallow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiaQWPbS36fb"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","    .filterBounds(fallow.geometry()) \\\n","    .filterDate('2023-09-01', '2023-09-30') \\\n","    .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], fallow.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = nicfi_planet.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        # Sample the image at the feature's geometry\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        # Convert the sampled dictionary to ensure all keys have non-null values\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Ensure that sampled values are added correctly to the feature\n","        return feature.set(sampled)\n","\n","    # Apply the add_bands function to each feature in the feature collection\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(fallow, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('Class', 'Fallow').set('Sub_class', 'Fallow').set('Year', '2023').set('Region', '???') #Annee = year, Sub-class = Type, Crop_Ncrop = class\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename the property \"Speculat\" to \"Speculatio\"\n","def rename_speculat_to_speculatio(feature):\n","    return rename_property(feature, 'Specult', 'Name') #name =Specult\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_speculat_to_speculatio)\n","\n","# Get the first few features to display their properties\n","features_to_display = merged2023_class_with_properties.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", merged2023_class_with_properties.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=merged2023_class_with_properties,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/sept_fallow_class_nicfi'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")\n"]},{"cell_type":"markdown","metadata":{"id":"AlrZn1F8xXkQ"},"source":["Vegitables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSEBk8mpxZpT"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","    .filterBounds(vegetables.geometry()) \\\n","    .filterDate('2023-09-01', '2023-09-30')  \\\n","    .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], vegetables.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = nicfi_planet.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        # Sample the image at the feature's geometry\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        # Convert the sampled dictionary to ensure all keys have non-null values\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Ensure that sampled values are added correctly to the feature\n","        return feature.set(sampled)\n","\n","    # Apply the add_bands function to each feature in the feature collection\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(vegetables, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('Class', 'Crop').set('Sub_class', 'Vegetables').set('Year', '2023').set('Region', '???') #Annee = year, Sub-class = Type, Crop_Ncrop = class\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename the property \"Speculat\" to \"Speculatio\"\n","def rename_speculat_to_speculatio(feature):\n","    return rename_property(feature, 'Speculat', 'Name') #name =Specult)\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_speculat_to_speculatio)\n","\n","# Get the first few features to display their properties\n","features_to_display = merged2023_class_with_properties.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", merged2023_class_with_properties.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=merged2023_class_with_properties,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/sept_vegetables_class_nicfi'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")"]},{"cell_type":"markdown","metadata":{"id":"R5ZtRg0DyI1n"},"source":["legumes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whfRzWnUtL3M"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","    .filterBounds(legumes.geometry()) \\\n","    .filterDate('2023-09-01', '2023-09-30') \\\n","    .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], legumes.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = nicfi_planet.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","        return feature.set(sampled)\n","\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(legumes, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('Class', 'Crop').set('Sub_class', 'Legumes').set('Year', '2023').set('Region', '???')\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename the property \"Speculat\" to \"Speculatio\"\n","def rename_speculat_to_speculatio(feature):\n","    return rename_property(feature, 'Speculat', 'Name')\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_speculat_to_speculatio)\n","\n","# List of properties to remove\n","properties_to_remove = [\n","    \"altitudeMo\", \"area\", \"begin\", \"descriptio\", \"drawOrder\", \"end\",\n","    \"extrude\", \"icon\", \"id\", \"layer\", \"path\", \"perimeter\", \"system_ind\",\n","    \"tessellate\", \"timestamp\", \"visibility\"\n","]\n","\n","# Function to remove specified properties from the feature collection\n","def remove_properties(data, properties_to_remove):\n","    def clean_feature(feature):\n","        for prop in properties_to_remove:\n","            feature = feature.set(prop, None)\n","        return feature\n","\n","    return data.map(clean_feature)\n","\n","# Remove the unwanted properties\n","final_data = remove_properties(merged2023_class_with_properties, properties_to_remove)\n","\n","# Function to rename the 'Name' property value based on given rules\n","def rename_name_property(feature):\n","    name = ee.String(feature.get('Name'))\n","    new_name = ee.Algorithms.If(name.equals('goundnut_mixed'), 'groundnut_mixed', name)\n","    new_name = ee.Algorithms.If(ee.String(new_name).equals('mixed_cowpea'), 'cowpea_mixed', new_name)\n","    return feature.set('Name', new_name)\n","\n","# Apply the renaming rule to 'Name' property\n","final_data = final_data.map(rename_name_property)\n","\n","# Get the first few features to display their properties\n","features_to_display = final_data.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", final_data.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=final_data,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/sept_legumes_class_nicfi'\n",")\n","\n","export_task.start()\n"]},{"cell_type":"markdown","metadata":{"id":"RcyI4AeJBiG2"},"source":["Cereals2 has mutimple unnecessary properties to be removed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bK5Bs4yU95mL"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","    .filterBounds(cereals2.geometry()) \\\n","    .filterDate('2023-09-01', '2023-09-30')  \\\n","    .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], cereals2.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = nicfi_planet.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        # Sample the image at the feature's geometry\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5, #5m for NICFI\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        # Convert the sampled dictionary to ensure all keys have non-null values\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Ensure that sampled values are added correctly to the feature\n","        return feature.set(sampled)\n","\n","    # Apply the add_bands function to each feature in the feature collection\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(cereals2, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('Class', 'Crop').set('Sub_class', 'Cereals').set('Year', '2023').set('Region', '???') #Annee = year, Sub-class = Type, Crop_Ncrop = class\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename properties to \"Name\"\n","def rename_to_name(feature):\n","    feature = rename_property(feature, 'Speculat', 'Name')\n","    feature = rename_property(feature, 'Specult', 'Name')\n","    feature = rename_property(feature, 'Speculatio', 'Name')\n","    #feature = rename_property(feature, 'Name', 'Name')\n","    return feature\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_to_name)\n","\n","# Specify the properties to retain (remove some unnecessary properties)\n","properties_to_retain = ['Class', 'Sub_class', 'Year', 'Region', 'Name', 'B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N','id' ]\n","\n","# Select only the specified properties\n","filtered_features = merged2023_class_with_properties.select(properties_to_retain)\n","\n","# Get the first few features to display their properties\n","features_to_display = filtered_features.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", filtered_features.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=filtered_features,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/sept_cereals_class_nicfi'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")\n"]},{"cell_type":"markdown","metadata":{"id":"ZRtMr1Zq2EHy"},"source":["Tree_Crops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pA3gKHXu2G6a"},"outputs":[],"source":["# Function to rename a property in a feature\n","def rename_property(feature, old_name, new_name):\n","    new_feature = feature.set(new_name, feature.get(old_name)).copyProperties(feature).set(old_name, None)\n","    return new_feature\n","\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Load NICFI/Planet imagery and filter by date and bounds of the polygons\n","nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","    .filterBounds(tree_crops.geometry()) \\\n","    .filterDate('2023-09-01', '2023-09-30')  \\\n","    .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], tree_crops.geometry())) \\\n","    .map(calculate_ndvi)\n","\n","# Select bands to use for classification\n","bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","# Reduce the image collection to median to get a single composite image\n","image = nicfi_planet.median().select(bands)\n","\n","# Function to sample data from the image and integrate with feature collection\n","def add_bands_to_fc(fc, image):\n","    def add_bands(feature):\n","        # Sample the image at the feature's geometry\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        # Convert the sampled dictionary to ensure all keys have non-null values\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Ensure that sampled values are added correctly to the feature\n","        return feature.set(sampled)\n","\n","    # Apply the add_bands function to each feature in the feature collection\n","    return fc.map(add_bands)\n","\n","# Integrate the bands into the feature collection\n","crop_with_bands = add_bands_to_fc(tree_crops, image)\n","\n","# Add new properties to each feature\n","def add_properties(feature):\n","    return feature.set('Class', 'Tree_crops').set('Sub_class', 'Tree_crops').set('Year', '2023').set('Region', '???') #Annee = year, Sub-class = Type, Crop_Ncrop = class\n","\n","merged2023_class_with_properties = crop_with_bands.map(add_properties)\n","\n","# Rename the property \"Speculat\" to \"Speculatio\"\n","def rename_speculat_to_speculatio(feature):\n","    return rename_property(feature, 'Speculat', 'Name') #name =Speculat)\n","\n","merged2023_class_with_properties = merged2023_class_with_properties.map(rename_speculat_to_speculatio)\n","\n","# Get the first few features to display their properties\n","features_to_display = merged2023_class_with_properties.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","properties_list = [feature['properties'] for feature in features_to_display]\n","\n","# Create a DataFrame\n","df = pd.DataFrame(properties_list)\n","\n","# Display the DataFrame\n","print(df.tail())\n","\n","# Debugging: Check the contents before export\n","print(\"Feature collection before export: \", merged2023_class_with_properties.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=merged2023_class_with_properties,\n","    description='Export Crop_normalized_2023 with classes',\n","    assetId='projects/ee-kkidia3/assets/sept_tree_crops_class_nicfi'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")"]},{"cell_type":"markdown","metadata":{"id":"LTAwoulw21t1"},"source":["### ALL 2023 Poylgons with NICFI Classes of bands and NDVI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwcANCBU3DmG"},"outputs":[],"source":["# Load individual rainfed 2023 crop feature collections\n","asset_2023 = {\n","    'tree_crops': ee.FeatureCollection('projects/ee-kkidia3/assets/tree_crops_nicfi_months'),\n","    'cereals': ee.FeatureCollection('projects/ee-kkidia3/assets/cereals_nicfi_months'),\n","    'legumes': ee.FeatureCollection('projects/ee-kkidia3/assets/legumes_nicfi_months'),\n","    'vegetables': ee.FeatureCollection('projects/ee-kkidia3/assets/vegetables_nicfi_months'),\n","    'fallow': ee.FeatureCollection('projects/ee-kkidia3/assets/fallow_nicfi_months')\n","}\n","\n","# Merge the feature collections into a single collection\n","merged_collection = asset_2023['tree_crops'] \\\n","    .merge(asset_2023['cereals']) \\\n","    .merge(asset_2023['legumes']) \\\n","    .merge(asset_2023['vegetables'])\\\n","    .merge(asset_2023['fallow'])\n","\n","# Define the export task\n","export_task = ee.batch.Export.table.toDrive(\n","    collection=merged_collection,\n","    description='sept_data_2023',\n","    fileFormat='geojson',\n","    folder='data_2023_class_nicfi',\n","    fileNamePrefix='sept_data_2023_2_class_nicfi'\n",")\n","\n","# # Debugging: Check the contents before export\n","# print(\"Feature collection before export: \", merged2023_class_with_properties.getInfo())\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection = merged_collection,\n","    description='data_2023_months',\n","    assetId='projects/ee-kkidia3/assets/data_2023_nicfi_months'\n",")\n","\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")\n","\n","# Check the status of the export\n","while export_task.active():\n","    print('Exporting... Status: {}'.format(export_task.status()))\n","    time.sleep(30)  # Check the status every 30 seconds\n","\n","print('Export completed. Status: {}'.format(export_task.status()))"]},{"cell_type":"markdown","metadata":{"id":"YcZXueOB-L9_"},"source":["### Renmae some features under \"Name\" Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuIumP3O6CZB"},"outputs":[],"source":["# Load the feature collection\n","foo9= ee.FeatureCollection('projects/ee-kkidia3/assets/vegetables_class_nicfi')\n","\n","# Function to rename the 'Name' property value based on given rules\n","def rename_name_property(feature):\n","    name = ee.String(feature.get('Name'))\n","    new_name = ee.Algorithms.If(name.equals('Okra'), 'okra', name) # in vegetables class\n","    # new_name = ee.Algorithms.If(name.equals('goundnut_mixed'), 'groundnut_mixed', name) ## in legumes sub class\n","    # new_name = ee.Algorithms.If(ee.String(new_name).equals('mixed_cowpea'), 'cowpea_mixed', new_name) ##  in legumes sub-class\n","    return feature.set('Name', new_name)\n","# Apply the renaming function to the feature collection\n","foo9 = foo9.map(rename_name_property)\n","\n","# Export the modified Feature Collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=foo9,\n","    description='Export_Crop_Renamed',\n","    assetId='projects/ee-kkidia3/assets/vegetables_class_nicfi_renamed' #renamed as legumes_class_nicfi\n",")\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"egtrLuJmX-JS"},"outputs":[],"source":["# @title ALL 2023 Poylgons with NICFI Classes of bands and NDVI +++++++++++++++ 12 Months\n","foo = ee.FeatureCollection('projects/ee-kkidia3/assets/vegetables_class_nicfi_renamed')\n","##################################################################################################################################################\n","# Function to normalize a band\n","def normalize_band(image, band_name, geometry):\n","    band = image.select(band_name)\n","    min_val = ee.Number(band.reduceRegion(ee.Reducer.min(), geometry, scale=10).get(band_name))\n","    max_val = ee.Number(band.reduceRegion(ee.Reducer.max(), geometry, scale=10).get(band_name))\n","    normalized_band = band.subtract(min_val).divide(max_val.subtract(min_val)).float()\n","    return normalized_band.rename(band_name + '_norm')\n","\n","# Function to normalize all specified bands\n","def normalize_bands(image, band_names, geometry):\n","    normalized_bands = [normalize_band(image, band_name, geometry) for band_name in band_names]\n","    return image.addBands(normalized_bands, overwrite=True)\n","\n","# Function to calculate NDVI\n","def calculate_ndvi(image):\n","    ndvi = image.normalizedDifference(['N', 'R']).rename('NDVI')\n","    return image.addBands(ndvi)\n","\n","# Function to add bands to the feature collection\n","def add_bands_to_fc(fc, image, month):\n","    def add_bands(feature):\n","        sampled = image.reduceRegion(\n","            reducer=ee.Reducer.mean(),\n","            geometry=feature.geometry(),\n","            scale=5,\n","            maxPixels=1e13,\n","            bestEffort=True\n","        )\n","        sampled = sampled.map(lambda k, v: ee.Algorithms.If(v, v, 0))\n","\n","        # Create month-specific properties\n","        keys = sampled.keys()\n","        values = keys.map(lambda k: sampled.get(k))\n","        month_sampled = ee.Dictionary.fromLists(keys.map(lambda k: ee.String(k).cat('_').cat(ee.Number(month).format())), values)\n","\n","        return feature.setMulti(month_sampled)\n","\n","    return fc.map(add_bands)\n","\n","# Function to get the last day of a given month\n","def get_last_day_of_month(year, month):\n","    next_month = (month % 12) + 1\n","    next_month_year = year if month < 12 else year + 1\n","    last_day = ee.Date(f'{next_month_year}-{next_month:02d}-01').advance(-1, 'day').format('yyyy-MM-dd')\n","    return last_day\n","\n","# Function to process data for a given month and year\n","def process_month(year, month):\n","    start_date = f'{year}-{month:02d}-01'\n","    end_date = get_last_day_of_month(year, month).getInfo()\n","\n","    nicfi_planet = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","        .filterBounds(foo.geometry()) \\\n","        .filterDate(start_date, end_date) \\\n","        .map(lambda image: normalize_bands(image, ['B', 'G', 'R', 'N'], foo.geometry())) \\\n","        .map(calculate_ndvi)\n","\n","    bands = ['B_norm', 'G_norm', 'R_norm', 'N_norm', 'NDVI', 'B', 'G', 'R', 'N']\n","\n","    image = nicfi_planet.median().select(bands)\n","\n","    crop_with_bands = add_bands_to_fc(foo, image, month)\n","\n","    return crop_with_bands\n","\n","# Process data for each month in 2023 and merge into a single feature collection\n","merged_feature_collection = foo\n","for month in range(1, 13):\n","    monthly_fc = process_month(2023, month)\n","    merged_feature_collection = merged_feature_collection.map(\n","        lambda f: f.setMulti(monthly_fc.filter(ee.Filter.eq('system:index', f.get('system:index'))).first().toDictionary())\n","    )\n","\n","    print(f'Processed month {month}...')\n","\n","# Export the merged feature collection to Google Earth Engine Asset\n","export_task = ee.batch.Export.table.toAsset(\n","    collection=merged_feature_collection,\n","    description='Export_vegetables_months',\n","    assetId='projects/ee-kkidia3/assets/vegetables_class_nicfi_renamed_months'\n","    )\n","\n","\n","# # Export the merged feature collection to Google Drive as GeoJSON\n","# export_task = ee.batch.Export.table.toDrive(\n","#     collection=merged_feature_collection,\n","#     description='Export_Crop_normalized_2023_to_Drive',\n","#     fileFormat='GeoJSON',\n","#     folder='foo6',\n","#     fileNamePrefix='foo6'\n","# )\n","export_task.start()\n","\n","print(\"Export task started. Check the Earth Engine Code Editor for task status.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":7532,"status":"ok","timestamp":1721516868178,"user":{"displayName":"Kidia","userId":"01506917662513131110"},"user_tz":0},"id":"2f2Pp1Jtj4Wy","outputId":"c30a28f3-421e-48a1-e398-5b5eda2eb13e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"},"text/html":["\n","  <div id=\"df-f853370f-5d49-4603-8ea0-ecf00ef76d8e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>B</th>\n","      <th>B_1</th>\n","      <th>B_10</th>\n","      <th>B_11</th>\n","      <th>B_12</th>\n","      <th>B_2</th>\n","      <th>B_3</th>\n","      <th>B_4</th>\n","      <th>B_5</th>\n","      <th>B_6</th>\n","      <th>...</th>\n","      <th>R_norm_4</th>\n","      <th>R_norm_5</th>\n","      <th>R_norm_6</th>\n","      <th>R_norm_7</th>\n","      <th>R_norm_8</th>\n","      <th>R_norm_9</th>\n","      <th>Region</th>\n","      <th>Sub_class</th>\n","      <th>Year</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>793.967797</td>\n","      <td>562.901458</td>\n","      <td>804.657593</td>\n","      <td>594.241187</td>\n","      <td>558.515172</td>\n","      <td>514.074223</td>\n","      <td>504.273836</td>\n","      <td>515.258144</td>\n","      <td>487.764391</td>\n","      <td>431.006024</td>\n","      <td>...</td>\n","      <td>0.210879</td>\n","      <td>0.203596</td>\n","      <td>0.205572</td>\n","      <td>0.240610</td>\n","      <td>0.409707</td>\n","      <td>0.395673</td>\n","      <td>???</td>\n","      <td>Tree_crops</td>\n","      <td>2023</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>736.538466</td>\n","      <td>575.151121</td>\n","      <td>729.273378</td>\n","      <td>591.958492</td>\n","      <td>562.291627</td>\n","      <td>529.610210</td>\n","      <td>506.465410</td>\n","      <td>523.047948</td>\n","      <td>541.390506</td>\n","      <td>515.292462</td>\n","      <td>...</td>\n","      <td>0.295722</td>\n","      <td>0.382847</td>\n","      <td>0.453650</td>\n","      <td>0.122955</td>\n","      <td>0.172472</td>\n","      <td>0.336460</td>\n","      <td>???</td>\n","      <td>Tree_crops</td>\n","      <td>2023</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>662.401625</td>\n","      <td>465.788166</td>\n","      <td>623.506855</td>\n","      <td>444.602136</td>\n","      <td>466.485234</td>\n","      <td>447.104052</td>\n","      <td>413.260734</td>\n","      <td>463.249237</td>\n","      <td>406.865309</td>\n","      <td>406.954010</td>\n","      <td>...</td>\n","      <td>0.181106</td>\n","      <td>0.181972</td>\n","      <td>0.216503</td>\n","      <td>0.257183</td>\n","      <td>0.257825</td>\n","      <td>0.224939</td>\n","      <td>???</td>\n","      <td>Tree_crops</td>\n","      <td>2023</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>658.475114</td>\n","      <td>532.622117</td>\n","      <td>676.540495</td>\n","      <td>547.975668</td>\n","      <td>545.063343</td>\n","      <td>502.563244</td>\n","      <td>510.996202</td>\n","      <td>562.685341</td>\n","      <td>522.697409</td>\n","      <td>531.518140</td>\n","      <td>...</td>\n","      <td>0.484181</td>\n","      <td>0.532204</td>\n","      <td>0.553644</td>\n","      <td>0.566756</td>\n","      <td>0.393534</td>\n","      <td>0.105061</td>\n","      <td>???</td>\n","      <td>Tree_crops</td>\n","      <td>2023</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>699.611807</td>\n","      <td>574.250786</td>\n","      <td>708.432271</td>\n","      <td>590.548435</td>\n","      <td>574.144886</td>\n","      <td>537.637467</td>\n","      <td>532.679715</td>\n","      <td>594.283327</td>\n","      <td>549.115129</td>\n","      <td>552.693002</td>\n","      <td>...</td>\n","      <td>0.562260</td>\n","      <td>0.596732</td>\n","      <td>0.565190</td>\n","      <td>0.659613</td>\n","      <td>0.431805</td>\n","      <td>0.219273</td>\n","      <td>???</td>\n","      <td>Tree_crops</td>\n","      <td>2023</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows  123 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f853370f-5d49-4603-8ea0-ecf00ef76d8e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f853370f-5d49-4603-8ea0-ecf00ef76d8e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f853370f-5d49-4603-8ea0-ecf00ef76d8e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9bea8497-1080-4cd3-8582-3ac941c2a992\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bea8497-1080-4cd3-8582-3ac941c2a992')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9bea8497-1080-4cd3-8582-3ac941c2a992 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["            B         B_1        B_10        B_11        B_12         B_2  \\\n","0  793.967797  562.901458  804.657593  594.241187  558.515172  514.074223   \n","1  736.538466  575.151121  729.273378  591.958492  562.291627  529.610210   \n","2  662.401625  465.788166  623.506855  444.602136  466.485234  447.104052   \n","3  658.475114  532.622117  676.540495  547.975668  545.063343  502.563244   \n","4  699.611807  574.250786  708.432271  590.548435  574.144886  537.637467   \n","\n","          B_3         B_4         B_5         B_6  ...  R_norm_4  R_norm_5  \\\n","0  504.273836  515.258144  487.764391  431.006024  ...  0.210879  0.203596   \n","1  506.465410  523.047948  541.390506  515.292462  ...  0.295722  0.382847   \n","2  413.260734  463.249237  406.865309  406.954010  ...  0.181106  0.181972   \n","3  510.996202  562.685341  522.697409  531.518140  ...  0.484181  0.532204   \n","4  532.679715  594.283327  549.115129  552.693002  ...  0.562260  0.596732   \n","\n","   R_norm_6  R_norm_7  R_norm_8  R_norm_9  Region   Sub_class  Year   id  \n","0  0.205572  0.240610  0.409707  0.395673     ???  Tree_crops  2023  6.0  \n","1  0.453650  0.122955  0.172472  0.336460     ???  Tree_crops  2023  7.0  \n","2  0.216503  0.257183  0.257825  0.224939     ???  Tree_crops  2023  4.0  \n","3  0.553644  0.566756  0.393534  0.105061     ???  Tree_crops  2023  3.0  \n","4  0.565190  0.659613  0.431805  0.219273     ???  Tree_crops  2023  2.0  \n","\n","[5 rows x 123 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# @title Test the exported GEE asset\n","xx = ee.FeatureCollection('projects/ee-kkidia3/assets/data_2023_nicfi_months')\n","# Get the first few features to display their properties\n","f_display =xx.limit(5000).getInfo()['features']  #Limited only 5000\n","\n","# Crop_2023_norm_bands_class = load_crop_data('projects/ee-kkidia3/assets/Crop_2023_No_norm_bands_class')\n","# # Get the first few features to display their properties\n","# f_display =Crop_2023_norm_bands_class.limit(5).getInfo()['features']\n","\n","# Extract properties into a list of dictionaries\n","p_list = [feature['properties'] for feature in f_display]\n","# Print the properties of the first few features\n","#for feature in features_to_display:\n","   # print(feature['properties'])\n","\n","# Create a DataFrame from the properties list\n","df = pd.DataFrame(p_list)\n","\n","df.head() #show it in data fram\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEjC0DxNA7v4"},"outputs":[],"source":["# @title Name\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","df.groupby('Name').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n","plt.gca().spines[['top', 'right',]].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UX1ZMgUprpuz"},"outputs":[],"source":["# @title Name vs NDVI September\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","figsize = (12, 1.2 * len(df['Class'].unique()))\n","plt.figure(figsize=figsize)\n","sns.violinplot(df, x='NDVI_9', y='Class', inner='box', palette='Dark2')\n","sns.despine(top=True, right=True, bottom=True, left=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80ov8WxwzFL2"},"outputs":[],"source":["# @title Name vs NDVI November\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","figsize = (12, 1.2 * len(df['Class'].unique()))\n","plt.figure(figsize=figsize)\n","sns.violinplot(df, x='NDVI_11', y='Class', inner='box', palette='Dark2')\n","sns.despine(top=True, right=True, bottom=True, left=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kVwyH6uphiN"},"outputs":[],"source":["# @title Mean NDVI by Crop Name\n","\n","import matplotlib.pyplot as plt\n","\n","mean_ndvi = df.groupby('Sub_class')['NDVI'].mean().sort_values()\n","\n","plt.figure(figsize=(10, 6))\n","plt.bar(mean_ndvi.index, mean_ndvi.values)\n","plt.xlabel('Crop Name')\n","plt.ylabel('Mean NDVI')\n","plt.title('Mean NDVI by Crop Name')\n","_ = plt.xticks(rotation=45, ha='right')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lerfH73AHfOr"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","_df_18['G_norm'].plot(kind='line', figsize=(8, 4), title='G_norm')\n","plt.gca().spines[['top', 'right']].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XrqM8npHPaS"},"outputs":[],"source":["print(xx.size().getInfo())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"et7251EPxELu"},"outputs":[],"source":["# Check for NaN or None values in the DataFrame\n","null_values = df.isnull().sum()\n","\n","# Filter properties that have NaN or None values\n","properties_with_nulls = null_values[null_values > 0]\n","\n","# Display the properties with NaN or None values and their count\n","print(properties_with_nulls)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoKw7ltZW__5"},"outputs":[],"source":["# @title Name vs B_norm\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","figsize = (12, 1.2 * len(df['Class'].unique()))\n","plt.figure(figsize=figsize)\n","sns.violinplot(df, x='B_norm', y='Class', inner='box', palette='Dark2')\n","sns.despine(top=True, right=True, bottom=True, left=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNw3X5kBWaVX"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","_df_28['B'].plot(kind='line', figsize=(8, 4), title='B')\n","plt.gca().spines[['top', 'right']].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQy3BLyQWSOi"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","_df_30['G'].plot(kind='line', figsize=(8, 4), title='G')\n","plt.gca().spines[['top', 'right']].set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0DPB1F0CVt6F"},"outputs":[],"source":["# @title B\n","\n","from matplotlib import pyplot as plt\n","df['B'].plot(kind='line', figsize=(8, 4), title='B')\n","plt.gca().spines[['top', 'right']].set_visible(False)"]},{"cell_type":"markdown","metadata":{"id":"Wtu_Up1sVv3r"},"source":["Sample randomforest calssification only gnut"]},{"cell_type":"markdown","metadata":{"id":"BbkKpj3Gjakc"},"source":["Remove overlapping polygons from your merged feature collection. Overlaps is due to data collection"]},{"cell_type":"markdown","metadata":{"id":"2cyMHrZPxdQr"},"source":["For example let me sort out only two polygons out of maney gnut polygons for closer look and simple analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","id":"-UXDK9RywbX3"},"outputs":[],"source":["# @title Default title text\n","# Select two specific polygons by their indices or properties. e.g gnut\n","# Here, I want to select the first two polygons.\n","poly_2 = gnut.toList(2)\n","\n","#print(poly_2)\n","\n","# Get the individual polygons\n","polygon1 = ee.Feature(poly_2.get(0))\n","polygon2 = ee.Feature(poly_2.get(1))\n","\n","# Print the geometries of the selected polygons to verify.\n","print('Polygon 1_Blue:', polygon1.geometry().getInfo())\n","print('Polygon 2_Red:', polygon2.geometry().getInfo())\n","\n","\n","# Create a map centered at an arbitrary point @polygon1\n","map_center = [13.237198228125724,-14.715474917616827]  #set this to a blue selected @polygon1\n","m = folium.Map(location=map_center, zoom_start=30) #\n","\n","# Define a function to add a feature to the folium map.\n","def add_feature_to_map(feature, map_obj, color):\n","    geom = feature.geometry().getInfo()\n","    coords = geom['coordinates']\n","    if geom['type'] == 'Polygon':\n","        folium.Polygon(locations=[(pt[1], pt[0]) for pt in coords[0]], color=color).add_to(map_obj)\n","    elif geom['type'] == 'MultiPolygon':\n","        for poly in coords:\n","            folium.Polygon(locations=[(pt[1], pt[0]) for pt in poly[0]], color=color).add_to(map_obj)\n","\n","# Add polygons to the map\n","add_feature_to_map(polygon1, m, 'blue')\n","add_feature_to_map(polygon2, m, 'red')\n","\n","# Display the map\n","m"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RRCWAtzMgXZ"},"outputs":[],"source":["# Calculate the total area of polygons in square meters for Rainfed season 2023. Example groundnut\n","area = gnut.geometry().area().format('%.1f').getInfo()\n","print(f\"Area M2: {area} square meters OR,\")\n","\n","# Calculate the area in hectares (1 hectare = 10,000 square meters)\n","area_ha = gnut.geometry().area().divide(10000).format('%.1f').getInfo() # Convert square meters to hectares\n","print(f\"Area Ha: {area_ha} hectares\")\n","\n","# Calculate the perimeter in meters\n","perimeter = gnut.geometry().perimeter().format('%.1f').getInfo()\n","print(f\"Perimeter: {perimeter} meters\")\n","\n","# Get the centroid of the polygon\n","centroid = gnut.geometry().centroid().getInfo()\n","print(f\"Centroid: {centroid}\")\n","\n","# Get the bounding box as a GeoJSON\n","bounding_box = gnut.geometry().bounds().getInfo()\n","print(f\"Bounding Box: {bounding_box}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rn2qJaFPJhVb"},"source":["### Estimate the each polygon area (m2), for each crop e.g Groundnt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ4Dh3yNIChw"},"outputs":[],"source":["# Define a function to calculate the area of each polygon in hectares\n","#def calc_area(feature):\n","    #return feature.set('area_ha', ee.Number(feature.geometry().area().divide(10000)).format('%.3f'))\n","\n","# Define a function to calculate the area of each polygon in m2\n","def calc_area(feature):\n","  return feature.set('area_m2', ee.Number(feature.geometry().area())\n","  .format('%.1f'))#.divide(10000)) & # .format('%.1f') use to limit the digits\n","\n","# Apply the function to each feature in the collection\n","area_mapped = merged2023.map(calc_area)\n","\n","# Fetch the mapped area information from the server\n","areas_info = area_mapped.limit(10).getInfo()  # Limiting to the first 10 features directly to show everthing remove .limit(10)\n","\n","# Iterate through the first 10 features and print area in hectares with 3 decimal places\n","for feature in areas_info['features']:\n","    area = feature['properties']['area_m2'] ##m2\n","    print(f\"Gnut Polygon_Area: {area} m2\") #m2\n"]},{"cell_type":"markdown","metadata":{"id":"hDwoYgNvPUjs"},"source":["### Area (ha) distributions e.g Groundnut"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bj9r9SdyNQOL"},"outputs":[],"source":["# Define a function to calculate the area of each polygon in hectares\n","#def calc_area(feature):\n","    #return feature.set('area_ha', feature.geometry().area().divide(10000))  # Convert from square meters to hectares\n","\n","# Define a function to calculate the area of each polygon in hectares\n","def calc_area(feature):\n","    return feature.set('area_ha', feature.geometry().area().divide(10000)) #--> # Convert from square meters to hectares\n","\n","# Apply the function to each feature in the collection\n","area_mapped = gnut.map(calc_area)\n","\n","# Extract and print the area of each polygon\n","areas_info = area_mapped.getInfo()\n","\n","# Extracting areas into a list for plotting\n","areas = [feature['properties']['area_ha'] for feature in areas_info['features']]\n","\n","# Plotting the distribution of polygon areas\n","plt.figure(figsize=(10, 6))\n","plt.hist(areas, bins='auto', color='skyblue', alpha=0.8, rwidth=0.85)\n","plt.title('Distribution of Polygon Areas in Ha for Groundnut')\n","plt.xlabel('Area (Ha)')\n","plt.ylabel('Frequency')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2uPvoOP8Uujo"},"source":["Show area of each crop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvCoUdYvUPu_"},"outputs":[],"source":["#  'gnut', 'gsorrel', 'rice', etc. are already defined as ee.Geometry() or ee.Feature() objects representing each crop\n","crop_types = {\n","    'Gnut': gnut,\n","    'G. Sorrel': gsorrel,\n","    'Rice': rice,\n","    'Sesame': sesame,\n","    'Soye': soye,\n","    'Watermelon': melon,\n","    'Cassava': cassava,\n","    'Gnut Mix': gnutmix,\n","    'Millet Mix': milletmix,\n","    'Okra': okra,\n","    'Sorgh': sorgh,\n","    'Wheat': wheat,\n","    'Millet': millet,\n","    'Cowpea Mix': cowpmix,\n","    'Fallow': fallow\n","}\n","\n","# Calculate area for each crop and store in a dictionary\n","#areas = {name: crop.geometry().area().divide(10000).getInfo() for name, crop in crop_types.items()} #In Hectares\n","areas = {name: crop.geometry().area().getInfo() for name, crop in crop_types.items()}\n","\n","\n","# Create a DataFrame from the area dictionary\n","area_df = pd.DataFrame(list(areas.items()), columns=['Crop Type', 'Area (Squere meteres M2)'])\n","\n","# Display the DataFrame\n","print(area_df)\n","\n","area_df.head(14)"]},{"cell_type":"markdown","metadata":{"id":"jF3CRVX0V1wl"},"source":["Graphic of each crop in area coverages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbKXQ5YfVRtK"},"outputs":[],"source":["area_df = pd.DataFrame(list(areas.items()), columns=['Crop Type', 'Area (M2)'])\n","\n","# Sort the DataFrame by area for better visualization\n","area_df.sort_values('Area (M2)', ascending=False, inplace=True)\n","\n","# Plotting\n","plt.figure(figsize=(12, 8))\n","plt.bar(area_df['Crop Type'], area_df['Area (M2)'], color='red')\n","plt.xlabel('Crop Type')\n","plt.ylabel('Area in M2')\n","plt.title('Area of Each Crop Type for FY2023')\n","plt.xticks(rotation=90)  # Rotate crop type names for better readability\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lOcmfMnU0CuD"},"source":["### Count Pixels (NICFI) for each crop field represnetation of each specteral bands e.g Groundnut"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2KnVvBp0XoH"},"outputs":[],"source":["# time range\n","start_date = '2023-09-01'\n","end_date = '2023-09-30'\n","\n","# Load the Planet/NICFI imagery\n","imagery = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa').filterDate(start_date, end_date).filterBounds(merged2023)  # Assuming 'gnut' is the ee.Geometry() of my area of interest\n","#bands info\n","bands = ee.ImageCollection(imagery).first()\n","print(bands.bandNames().getInfo())\n","\n","#################  Planet Pixel count ####### Actual pixel count from PLANET\n","\n","# Function to mask and count pixels within the 'gnut' polygon\n","def count_pixels(image):\n","    # Mask the image with the polygon\n","    masked_image = image.clip(gnut) #remember 1 polygone selected for closer see demo\n","\n","    # Count pixels - 4.77 X 4.77 m (~5X5m) actual Planet/NICFI pixel resolution\n","    pixel_count = masked_image.reduceRegion(\n","        reducer=ee.Reducer.count(),\n","        geometry=gnut,\n","        scale=4.77,  # Scale in meters; 5m resolution take time to estimate (timeout)\n","        # to avoid time out estimation use 10X10m and convert it in to 5X5 by devide the result 4\n","        maxPixels=1e9  # Adjust maxPixels if needed to handle large areas\n","    )\n","\n","    # Need to return an ee.Feature for the .map() function\n","    return ee.Feature(None, pixel_count)\n","\n","# Apply the pixel counting to each image in the collection\n","pixel_counts = imagery.map(count_pixels)\n","\n","# Get information from the ImageCollection\n","pixel_counts_info = pixel_counts.getInfo()\n","\n","# Print out the results\n","for feature in pixel_counts_info['features']:\n","    print(feature['properties'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzGYAjPY9tf0"},"outputs":[],"source":["# Define the time range\n","start_date = '2023-09-01'\n","end_date = '2023-09-30'\n","\n","\n","# Load the Planet/NICFI imagery\n","imagery = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa') \\\n","            .filterDate(start_date, end_date) \\\n","            .filterBounds(merged2023)\n","\n","# Print band information\n","bands = imagery.first()\n","print(bands.bandNames().getInfo())\n","\n","# Function to mask and count pixels within the AOI\n","def count_pixels(image):\n","    # Mask the image with the polygon\n","    masked_image = image.clip(merged2023)\n","\n","    # Count pixels - 10m resolution for faster computation\n","    pixel_count = masked_image.reduceRegion(\n","        reducer=ee.Reducer.count(),\n","        geometry=merged2023,\n","        scale=10,  # Scale in meters; coarser resolution for faster computation\n","        maxPixels=1e6  # Adjust maxPixels if needed to handle large areas\n","    )\n","\n","    # Need to return an ee.Feature for the .map() function\n","    return ee.Feature(None, pixel_count)\n","\n","# Apply the pixel counting to each image in the collection\n","pixel_counts = imagery.map(count_pixels)\n","\n","# Get information from the ImageCollection\n","pixel_counts_info = pixel_counts.getInfo()\n","\n","# Print out the results\n","for feature in pixel_counts_info['features']:\n","    print(feature['properties'])"]},{"cell_type":"markdown","metadata":{"id":"jKC_1ils9tNo"},"source":[]},{"cell_type":"markdown","metadata":{"id":"FJAcGlTUfoKE"},"source":["### pixel esimates for each crop considering area not pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaJnKXD9Z6l7"},"outputs":[],"source":["# Assuming these are the individual crop polygons. others to be added from other crop years.\n","crop_types = {\n","    'gnut': gnut, 'gsorrel': gsorrel, 'rice': rice, 'sesame': sesame,\n","    'soye': soye, 'watermelon': melon, 'cassava': cassava,\n","    'gnutmix': gnutmix, 'milletmix': milletmix, 'okra': okra,\n","    'sorgh': sorgh, 'wheat': wheat, 'millet': millet, 'cowpmix': cowpmix,\n","    'fallow': fallow\n","}\n","\n","def count_pixels(crop_name, crop_polygon):\n","    # Filter the imagery to the bounds of the crop polygon\n","    crop_imagery = imagery.filterBounds(crop_polygon)\n","\n","    # Apply the pixel counting for each image in the filtered collection\n","    def pixel_count(image):\n","        masked_image = image.clip(crop_polygon)\n","        pixel_count = masked_image.reduceRegion(\n","            reducer=ee.Reducer.count(),\n","            geometry=crop_polygon,\n","            scale=10,  # Adjust the scale based on the actual resolution of NICFI imagery\n","            maxPixels=1e9\n","        )\n","        return ee.Feature(None, pixel_count)\n","\n","    pixel_counts = crop_imagery.map(pixel_count)\n","    pixel_counts_info = pixel_counts.getInfo()\n","\n","    # Print results for each crop type\n","    print(crop_name)\n","    for feature in pixel_counts_info['features']:\n","        print(feature['properties'])\n","\n","# Run the pixel counting for each crop type\n","for crop_name, crop_polygon in crop_types.items():\n","    count_pixels(crop_name, crop_polygon)"]},{"cell_type":"markdown","metadata":{"id":"qXZyvvqShrCc"},"source":["### Pixel Exclusion representes less (e.g 40%) with in inside the polygon area.\n","\n","Masking Pixels: Pixels with less than 40% coverage by the polygon are excluded using the mask method, where mask = fraction.gte(0.4) creates a mask that includes only pixels where the fraction is 40% or more."]},{"cell_type":"markdown","metadata":{"id":"PEJuJdTiiXr8"},"source":["- Band Selection: When creating the mask, the code now ensures that a single band is selected using image.select(0). This selects the first band of the image, assuming the first band is suitable for your masking purposes. Adjust the band selection if necessary based on the bands available in your specific imagery.\n","\n","- Mask Application: By using single_band_image.mask() in the fraction calculation, we ensure that any operations involving masks deal with a single-band image, thus avoiding band mismatch errors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Mj5TnDQhkEx"},"outputs":[],"source":["# Function to mask and count pixels within the 'gnut' polygon\n","def count_pixels(image):\n","    # Ensure that we work with a single band for mask creation\n","    # Here, you could potentially select a specific band or reduce to a single band\n","    # As an example, if the image has multiple bands, use just one (e.g., the first band) for mask calculations\n","    single_band_image = image.select(1)\n","\n","    # Calculate the fraction of the pixel area that overlaps with the polygon using a constant image\n","    constantImage = ee.Image.constant(1).clip(okra)\n","    fraction = constantImage.updateMask(single_band_image.mask()).reduceRegion(\n","        reducer=ee.Reducer.mean(),\n","        geometry=gnut,\n","        scale=5,  # estimation with planet 5x5 is very difficult\n","        maxPixels=1e9\n","    ).get('constant')\n","\n","    # Threshold the fraction to include only pixels with >= 40% coverage\n","    mask = ee.Image(fraction).gte(0.4)\n","\n","    # Mask the image with the calculated mask\n","    masked_image = image.updateMask(mask)\n","\n","    # Count pixels\n","    pixel_count = masked_image.reduceRegion(\n","        reducer=ee.Reducer.count(),\n","        geometry=gnut,\n","        scale=5,\n","        maxPixels=1e9\n","    )\n","\n","    # Return an ee.Feature for the .map() function to work properly\n","    return ee.Feature(None, pixel_count)\n","\n","# Apply the pixel counting to each image in the collection\n","pixel_counts = imagery.map(count_pixels)\n","\n","# Get information from the ImageCollection\n","pixel_counts_info = pixel_counts.getInfo()\n","\n","# Print out the results\n","for feature in pixel_counts_info['features']:\n","    print(feature['properties'])"]},{"cell_type":"markdown","metadata":{"id":"9k0jFk_e9ChT"},"source":["only one polygon from gnut only for learning use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJhG_Dmb8zna"},"outputs":[],"source":["# Function to mask and count pixels within the 'gnut' polygon\n","def count_pixels(image):\n","    # Ensure that we work with a single band for mask creation\n","    single_band_image = image.select(1)  # Select the first band (assuming 1-based index)\n","\n","    # Calculate the fraction of the pixel area that overlaps with the polygon using a constant image\n","    constant_image = ee.Image.constant(1).clip(polygon1)\n","    fraction = constant_image.updateMask(single_band_image.mask()).reduceRegion(\n","        reducer=ee.Reducer.mean(),\n","        geometry=gnut.geometry(),\n","        scale=5,  # estimation with planet 5x5 is very difficult\n","        maxPixels=1e9\n","    ).get('constant')\n","\n","    # Threshold the fraction to include only pixels with >= 40% coverage\n","    mask = ee.Image.constant(fraction).gte(0.4)\n","\n","    # Mask the image with the calculated mask\n","    masked_image = image.updateMask(mask)\n","\n","    # Count pixels\n","    pixel_count = masked_image.reduceRegion(\n","        reducer=ee.Reducer.count(),\n","        geometry=gnut.geometry(),\n","        scale=5,\n","        maxPixels=1e9\n","    )\n","\n","    # Return an ee.Feature for the .map() function to work properly\n","    return ee.Feature(None, pixel_count)\n","\n","# Apply the pixel counting to each image in the collection\n","pixel_counts = imagery.map(count_pixels)\n","\n","# Get information from the ImageCollection\n","pixel_counts_info = pixel_counts.getInfo()\n","\n","# Print out the results\n","for feature in pixel_counts_info['features']:\n","    print(feature['properties'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ILNKnZCXKUX"},"outputs":[],"source":["# Function to mask and count pixels within the 'gnut' polygon\n","def count_pixels(image):\n","    # Create a single band composite by averaging RGB and NIR bands\n","    composite = image.expression(\n","        \"(R + G + B + N) / 4\",  # Expression combining the bands\n","        {\n","            'R': image.select('R'),  #  'R' is the Red band\n","            'G': image.select('G'),  # 'G' is the Green band\n","            'B': image.select('B'),  #  'B' is the Blue band\n","            'N': image.select('N')   #  'N' is the NIR band\n","        }\n","    )\n","\n","    # Generate a mask based on the composite value, adjusting threshold as necessary\n","    mask = composite.gt(0.2)  # Example threshold\n","\n","    # Mask the image with the generated mask\n","    masked_image = image.updateMask(mask)\n","\n","    # Count pixels\n","    pixel_count = masked_image.reduceRegion(\n","        reducer=ee.Reducer.count(),\n","        geometry=gnut,\n","        scale=5,\n","        maxPixels=1e9\n","    )\n","\n","    # Return an ee.Feature for the .map() function to work properly\n","    return ee.Feature(None, pixel_count)\n","\n","# Apply the pixel counting to each image in the collection\n","pixel_counts = imagery.map(count_pixels)\n","\n","# Get information from the ImageCollection\n","pixel_counts_info = pixel_counts.getInfo()\n","\n","# Print out the results\n","for feature in pixel_counts_info['features']:\n","    print(feature['properties'])"]},{"cell_type":"markdown","metadata":{"id":"4A-gnC1OuL9G"},"source":["Pixel counts using area coverage regardless of the specteral bands (NICFI + 4.77m X 4.77 M resolutions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Bi2CGb9hUmU"},"outputs":[],"source":["resolution = 4.77  # Resolution of NICFI imagery in meters (4.77m x 4.77m per pixel)\n","\n","\n","# Function to calculate pixel count\n","def calculate_pixels(crop):\n","    area = crop.geometry().area()  # Area in square meters\n","    pixel_area = resolution * resolution  # Area of one pixel in square meters\n","    pixel_count = area.divide(pixel_area)  # Number of pixels\n","    return pixel_count.getInfo()\n","\n","# Calculate pixel count for each crop and store in a dictionary\n","pixel_counts = {name: calculate_pixels(crop) for name, crop in crop_types.items()}\n","\n","# Create a DataFrame from the area and pixel count dictionaries\n","area_df = pd.DataFrame(list(pixel_counts.items()), columns=['Crop Type', 'Pixel Count'])\n","\n","# Sort the DataFrame by 'Pixel Count' in descending order\n","area_df = area_df.sort_values(by='Pixel Count', ascending=False)\n","# Display the DataFrame\n","print(area_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jjx1cZ7akX9y"},"outputs":[],"source":["# Plotting\n","#plt.figure(figsize=(10, 6))\n","#plt.bar(area_df['Crop Type'], area_df['Pixel Count'], color='green')\n","#plt.xlabel('Crop Type')\n","#plt.ylabel('Pixel Count')\n","#plt.title('Pixel Count by Crop Type (Ascending Order)')\n","#plt.xticks(rotation=45, ha='right')\n","#plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n","#plt.show()\n","####################\n","# Plotting using seaborn lib.\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='Crop Type', y='Pixel Count', data=area_df, palette='viridis')  # Using 'viridis' palette for varying colors\n","plt.xlabel('Crop Type')\n","plt.ylabel('Pixel Count')\n","plt.title('Pixel Count by Crop Type - for data base 2(FY2023)')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VQ6KJlrreX7K"},"source":["Area vs Pixel count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mE924kWEev5z"},"outputs":[],"source":["# Assuming 'crop_types' dictionary is predefined with ee.Geometry() objects\n","resolution = 4.77  # Resolution of NICFI imagery in meters\n","\n","# Function to calculate pixel count\n","def calculate_pixels(area):\n","    pixel_area = resolution * resolution  # Area of one pixel in square meters\n","    return area / pixel_area\n","\n","# Calculate area and pixel count for each crop and store in dictionaries\n","area_and_pixels = []\n","for name, crop in crop_types.items():\n","    area = crop.geometry().area().getInfo()  # Area in square meters\n","    pixel_count = calculate_pixels(area)\n","    area_and_pixels.append((name, area, pixel_count))\n","\n","# Create a DataFrame from the results\n","df = pd.DataFrame(area_and_pixels, columns=['Crop Type', 'Area (Square Meters)', 'Pixel Count'])\n","\n","# Sort the DataFrame by 'Pixel Count' in descending order (optional)\n","df.sort_values(by='Pixel Count', ascending=False, inplace=True)\n","\n","# Plotting\n","fig, ax1 = plt.subplots(figsize=(14, 8))\n","\n","# Bar plot for Area using Seaborn\n","color = 'tab:red'\n","sns.barplot(x='Crop Type', y='Area (Square Meters)', data=df, palette='viridis', ax=ax1)\n","ax1.set_xlabel('Crop Type')\n","ax1.set_ylabel('Area (Square Meters)', color=color)\n","ax1.tick_params(axis='y', labelcolor=color)\n","\n","# Create a twin Axes sharing the x-axis for Pixel Count\n","ax2 = ax1.twinx()\n","color = 'tab:blue'\n","sns.lineplot(x='Crop Type', y='Pixel Count', data=df, sort=False, marker='o', color='red', ax=ax2)\n","ax2.set_ylabel('Pixel Count', color=color)\n","ax2.tick_params(axis='y', labelcolor=color)\n","\n","# Improve layout and set x-axis labels rotation\n","plt.xticks(rotation=90)\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"istZFBD0pNjF"},"source":["### Garba\n","\n","Hi Garba, please use the above functions and generate the mean/median pixel specteral band values for \"R\", \"G\", \"B\" and \"N\" values of each pixel for each crop. Let me know if you need my assitance or have questions on the above functions. Perhaps you can show it in vector/tabular form.\n","\n","--------------------------------\n","R      |    G  |     B  |     N\n","-------------------------------\n","       |       |        |  "]},{"cell_type":"markdown","metadata":{"id":"wp0LBrEmCF9E"},"source":["**Steps**"]},{"cell_type":"markdown","metadata":{"id":"qPf6cPF1Sak1"},"source":["To enhance the quality and usability of the images for further analysis or applications Normalization and calibration of images are essential processes in image processing and computer vision.  "]},{"cell_type":"markdown","metadata":{"id":"J9_EfsreQFHk"},"source":["**1. Data Collection**: Obtain multispectral images of the crops that include the required spectral bands (R, G, B, and NIR)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9VAcmv-QGQy"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"vW0KWuhtQdRJ"},"source":["**2. Image Preprocessing**:"]},{"cell_type":"markdown","metadata":{"id":"BmSmJNVOSxOZ"},"source":["2.1. Image Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yypQbbs4S0pX"},"outputs":[],"source":["\n","\n","# Load the image\n","image = cv2.imread('/path/to/your/image.jpg')\n","\n","# Convert BGR image to RGB\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","# Normalize the image to range [0, 1]\n","normalized_image = image / 255.0\n","\n","# Alternatively, you can normalize to range [-1, 1]\n","# normalized_image = (image / 127.5) - 1.0\n","\n","# Display the original and normalized images\n","plt.subplot(1, 2, 1)\n","plt.title('Original Image')\n","plt.imshow(image)\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Normalized Image')\n","plt.imshow(normalized_image)\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"6bEH3KzTQnKp"},"source":["2.2. Calibration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxc9YkgeQtQS"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import glob\n","\n","# Termination criteria for corner sub-pixel accuracy\n","criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n","\n","# Prepare object points (0,0,0), (1,0,0), (2,0,0), ..., (6,5,0)\n","objp = np.zeros((6*7, 3), np.float32)\n","objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n","\n","# Arrays to store object points and image points from all images\n","objpoints = []  # 3d points in real world space\n","imgpoints = []  # 2d points in image plane\n","\n","# Load calibration images\n","images = glob.glob('/path/to/calibration/images/*.jpg')\n","\n","for fname in images:\n","    img = cv2.imread(fname)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Find the chessboard corners\n","    ret, corners = cv2.findChessboardCorners(gray, (7, 6), None)\n","\n","    # If found, add object points, image points (after refining them)\n","    if ret:\n","        objpoints.append(objp)\n","        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n","        imgpoints.append(corners2)\n","\n","        # Draw and display the corners\n","        img = cv2.drawChessboardCorners(img, (7, 6), corners2, ret)\n","        cv2.imshow('img', img)\n","        cv2.waitKey(500)\n","\n","cv2.destroyAllWindows()\n","\n","# Perform camera calibration\n","ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n","\n","# Save the calibration results\n","np.savez('calibration_data.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n","\n","# Undistort an image using the calibration results\n","img = cv2.imread('/path/to/your/test/image.jpg')\n","h, w = img.shape[:2]\n","newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n","\n","# Undistort\n","dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n","\n","# Crop the image\n","x, y, w, h = roi\n","dst = dst[y:y+h, x:x+w]\n","\n","# Display the result\n","cv2.imshow('calibrated', dst)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{"id":"dHp5FV9LQwZu"},"source":["2.3. Alignment"]},{"cell_type":"markdown","metadata":{"id":"VXSHt0wTOjKa"},"source":["  **  Install OpenCV**: Install OpenCV in your Colab environment to use its functionalities.\n","\n","    **Load and Display Images**: Load the two images you want to align. Display them using Matplotlib to ensure they are loaded correctly.\n","\n","    **Detect ORB Features and Compute Descriptors**: Use the ORB detector to find keypoints and compute descriptors for both images.\n","\n","    **Match Features Using BFMatcher**: Match the descriptors using BFMatcher, and sort the matches based on their distance (quality).\n","\n","    **Find Homography and Warp Image**: Extract the coordinates of the matched points, compute the homography matrix using RANSAC, and apply the homography to warp the second image to align it with the first image."]},{"cell_type":"markdown","metadata":{"id":"goAziACvPDk3"},"source":["1. **Install OpenCV**: First, ensure you have OpenCV installed in your Colab environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHbd1sgXPHo7"},"outputs":[],"source":["!pip install opencv-python-headless\n"]},{"cell_type":"markdown","metadata":{"id":"oPIGL4ENPLSw"},"source":["**2. Load and Display Images**: Load the images you want to align."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOmwztSFPTVD"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load the images in grayscale\n","img1 = cv2.imread('/path/to/your/image1.jpg', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/path/to/your/image2.jpg', cv2.IMREAD_GRAYSCALE)\n","\n","# Display the images\n","plt.subplot(1, 2, 1)\n","plt.title('Image 1')\n","plt.imshow(img1, cmap='gray')\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Image 2')\n","plt.imshow(img2, cmap='gray')\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"e322vR2IPWSJ"},"source":["**3. Detect ORB Features and Compute Descriptor**s:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEY3EivzPcmu"},"outputs":[],"source":["# Initialize the ORB detector\n","orb = cv2.ORB_create()\n","\n","# Detect keypoints and compute descriptors\n","keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n","keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n"]},{"cell_type":"markdown","metadata":{"id":"MAFunTOGPf9o"},"source":["**4. Match Features Using BFMatcher**:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjYdzM1BPo8B"},"outputs":[],"source":["# Create BFMatcher object\n","bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n","\n","# Match descriptors\n","matches = bf.match(descriptors1, descriptors2)\n","\n","# Sort them in the order of their distance\n","matches = sorted(matches, key=lambda x: x.distance)\n","\n","# Draw top matches\n","img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","\n","# Display the matches\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_matches)\n","plt.title('Feature Matches')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"g7L70895PwYz"},"source":["**5. Find Homography and Warp Image:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnjJP9wvOwpS"},"outputs":[],"source":["# Extract location of good matches\n","points1 = np.zeros((len(matches), 2), dtype=np.float32)\n","points2 = np.zeros((len(matches), 2), dtype=np.float32)\n","\n","for i, match in enumerate(matches):\n","    points1[i, :] = keypoints1[match.queryIdx].pt\n","    points2[i, :] = keypoints2[match.trainIdx].pt\n","\n","# Find homography matrix\n","h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n","\n","# Use homography to warp the image\n","height, width = img1.shape\n","aligned_img = cv2.warpPerspective(img2, h, (width, height))\n","\n","# Display the aligned image\n","plt.figure(figsize=(10, 10))\n","plt.subplot(1, 2, 1)\n","plt.title('Reference Image')\n","plt.imshow(img1, cmap='gray')\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Aligned Image')\n","plt.imshow(aligned_img, cmap='gray')\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"dbVIGmM0MZ4a"},"source":["**Extract Pixel Values: Extract the pixel values for each spectral band (R, G, B, NIR) for each segmented crop area.**"]},{"cell_type":"markdown","metadata":{"id":"Y7pwVmGkQ2sU"},"source":["Clipping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dqHNv9zQ6kL"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"f9X91TDhQ63t"},"source":["3. **Segmentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcx5V2x7RFcE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"j2b-hNkOR7H6"},"source":["**4. Extract Pixel Values**: Extract the pixel values for each spectral band (R, G, B, NIR) for each segmented crop area."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjFFEtWvR97w"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MS2G36cPSCTg"},"source":[]},{"cell_type":"markdown","metadata":{"id":"JVd_6vKWMcwM"},"source":["**5. Compute Statistics:**\n","\n","    Mean: Calculate the mean value for each spectral band across all pixels for each crop.\n","    Median: Calculate the median value for each spectral band across all pixels for each crop."]},{"cell_type":"markdown","metadata":{"id":"paLLSEy7GqzS"},"source":["### Cyrille\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwxxInMsG5Aa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"myjnM5EYfOBA"},"source":["**GARBA**  Other Proposition"]},{"cell_type":"markdown","metadata":{"id":"H1koAg51fR0v"},"source":[]},{"cell_type":"markdown","metadata":{"id":"U13_ffz19_4S"},"source":["[**Click Here for the first step to follow**](https://code.earthengine.google.com/91904df41cc77089f346977c173a0122)"]},{"cell_type":"markdown","metadata":{"id":"_8Y9N4Ny_H3T"},"source":["Change the variable to our variable\n","\n","1.   Area of Interest(roi)\n","2.   Land cover entities\n","3.   Filter the date\n","4.   Setup the other parameters for the convenance  \n"]},{"cell_type":"markdown","metadata":{"id":"jvaGAoM3fbL-"},"source":["Install some packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMIrI88_fpF7"},"outputs":[],"source":["!pip install rasterio\n","!pip install earthpy\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dxwz3-lzgUvO"},"outputs":[],"source":["#Import packages\n","import pandas as pd\n","import numpy as np\n","import keras\n","from keras import sequential\n","from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Input, GlobalMawPooling1D\n","from keras.callbacks import EarlyStopping\n","from kera import Model\n","import rasterio\n","import earth.plot as ep\n","from keras.utils import to_categorical\n","import sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, Classification_report\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import from_levels_and_colors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EHxdqr3Vgpla"},"outputs":[],"source":["#Mount GDRIVE\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"wNOesrFqjnXm"},"source":[]},{"cell_type":"markdown","metadata":{"id":"zk_oCPdRjWcy"},"source":["Drive already mounted at/content/drive; to attemp to forcibly remount, call drive.mount(\"/content/drive\" force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"Xp37g2MLi6h4"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOO4LRyLkY60"},"outputs":[],"source":["# Parameter\n","FEATURES = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'EVI', 'NBR', 'NDMI', 'NDWI', 'NDBI', 'NDBaI', 'elevation']\n","LABEL = ['classvalue']\n","SPLIT = ['sample']\n","N_CLASSES = 9\n","CLASSES = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n","PALETTE = ['#F08080', '#D2B48C', '#87CEFA', '#008080', '#90EE90', '#228B22', '#808000', '#FF8C00', '#006400']\n","SAMPLE_PATH = '/content/drive/MyDrive/DL/Samples_LC_Jambi_2023.csv'\n","IMAGE_PATH = '/content/drive/MyDrive/DL/Landsat_Jambi_2023.tif'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpSnMGQ_7UJe"},"outputs":[],"source":["# Load image\n","image = rasterio.open(IMAGE_PATH)\n","bandNum = image.count\n","height = image.height\n","width = image.width\n","crs = image.crs\n","transform = image.transform\n","shape = (height, width)\n","\n","image_vis = []\n","for x in [6, 5, 4]:\n","  image_vis.append(image.read(x))\n","image_vis = np.stack(image_vis)\n","\n","plot_size = (8, 8)\n","ep.plot_rgb(\n","  image_vis,\n","  figsize=plot_size,\n","  stretch=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNeYJkf47Vjc"},"outputs":[],"source":["# Read sample\n","samples = pd.read_csv(SAMPLE_PATH)\n","samples = samples.sample(frac = 1) # Shuffle data\n","samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hetXu1KB7lRR"},"outputs":[],"source":["# Split into train and test based on column\n","train = samples[samples['sample'] == 'train']\n","test = samples[samples['sample'] == 'test']\n","\n","# Split between features and label\n","train_features = train[FEATURES]\n","train_label = train[LABEL]\n","test_features = test[FEATURES]\n","test_label = test[LABEL]\n","\n","# Function to reshape array input\n","def reshape_input(array):\n","  shape = array.shape\n","  return array.reshape(shape[0], shape[1], 1)\n","\n","# Convert samples dataframe (pandas) to numpy array\n","train_input = reshape_input(train_features.to_numpy())\n","test_input = reshape_input(test_features.to_numpy())\n","\n","# Also make label data to categorical\n","train_output = to_categorical(train_label.to_numpy(), N_CLASSES + 1, int)\n","test_output = to_categorical(test_label.to_numpy(), N_CLASSES + 1, int)\n","\n","# Show the data shape\n","print(f'Train features: {train_input.shape}\\nTest features: {test_input.shape}\\nTrain label: {train_output.shape}\\nTest label: {test_output.shape}')"]},{"cell_type":"markdown","metadata":{"id":"VbTZopVG7y6L"},"source":["Train features: (14853, 14, 1)\n","Test features: (4043, 14, 1)\n","Train label: (14853, 10)\n","Test label: (4043, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eg5xlKwj70hr"},"outputs":[],"source":["# Make model for our data\n","# Input shape\n","train_shape = train_input.shape\n","input_shape = (train_shape[1], train_shape[2])\n","\n","# Model parameter\n","neuron = 64\n","drop = 0.2\n","kernel = 2\n","pool = 2\n","\n","# Make sequential model\n","model = Sequential([\n","  Input(input_shape),\n","  Conv1D(neuron * 1, kernel, activation='relu'),\n","  Conv1D(neuron * 1, kernel, activation='relu'),\n","  MaxPooling1D(pool),\n","  Dropout(drop),\n","  Conv1D(neuron * 2, kernel, activation='relu'),\n","  Conv1D(neuron * 2, kernel, activation='relu'),\n","  MaxPooling1D(pool),\n","  Dropout(drop),\n","  GlobalMaxPooling1D(),\n","  Dense(neuron * 2, activation='relu'),\n","  Dropout(drop),\n","  Dense(neuron * 1, activation='relu'),\n","  Dropout(drop),\n","  Dense(N_CLASSES + 1, activation='softmax')\n","])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LrRmOi-8HbG"},"outputs":[],"source":["# Train the model\n","\n","# Compline the model\n","model.compile(\n","    optimizer='Adam',\n","    loss='CategoricalCrossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Create callback to stop training if loss not decreasing\n","stop = EarlyStopping(\n","    monitor='loss',\n","    patience=5\n",")\n","\n","# Fit the model\n","result = model.fit(\n","    x=train_input, y=train_output,\n","    validation_data=(test_input, test_output),\n","    batch_size=1024,\n","    callbacks=[stop],\n","    epochs=100,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQjK3ddi79xf"},"outputs":[],"source":["# Show history\n","history = pd.DataFrame(result.history)\n","\n","plt.figure(figsize = (10, 8))\n","plt.plot(range(len(history['accuracy'].values.tolist())), history['accuracy'].values.tolist(), label = 'Train_Accuracy')\n","plt.plot(range(len(history['loss'].values.tolist())), history['loss'].values.tolist(), label = 'Train_Loss')\n","plt.plot(range(len(history['val_accuracy'].values.tolist())), history['val_accuracy'].values.tolist(), label = 'Test_Accuracy')\n","plt.plot(range(len(history['val_loss'].values.tolist())), history['val_loss'].values.tolist(), label = 'Test_Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Value')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDJoUR758jEU"},"outputs":[],"source":["# Predict test data\n","prediction = np.argmax(model.predict(test_input), 1).flatten()\n","label = np.argmax(test_output, 1).flatten()\n","\n","# Confusion matrix\n","cm = confusion_matrix(label, prediction, normalize='true')\n","cm = ConfusionMatrixDisplay(cm)\n","cm.plot()\n","\n","# Classification report\n","print(classification_report(label, prediction))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I6kCV2i8kH0"},"outputs":[],"source":["# Predict image using the model\n","image_input = []\n","for x in range(14):\n","  image_input.append(image.read(x + 1))\n","image_input = reshape_input(np.stack(image_input).reshape(14, -1).T)\n","\n","# Predict\n","prediction = model.predict(image_input, batch_size=4096*20)\n","prediction = np.argmax(prediction, 1)\n","prediction = prediction.reshape(shape[0], shape[1])\n","\n","# Visualize\n","cmap, norm = from_levels_and_colors(CLASSES, PALETTE, extend='max')\n","ep.plot_bands(prediction, cmap=cmap, norm=norm, figsize=plot_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OIrjTHJ8s7I"},"outputs":[],"source":["# Save file to drive\n","save_location = '/content/drive/MyDrive/DL/'\n","name = 'LC_Jambi_2023.tif'\n","location = save_location + name\n","\n","new_dataset = rasterio.open(\n","      location,\n","      mode='w', driver='GTiff',\n","      height = prediction.shape[0], width = prediction.shape[1],\n","      count=1, dtype=str(prediction.dtype),\n","      crs=crs,\n","      transform=transform\n",")\n","new_dataset.write(prediction, 1);\n","new_dataset.close()"]},{"cell_type":"markdown","metadata":{"id":"4bilAgHAAMg4"},"source":["For following step by step [Youtube Chanel](https://www.youtube.com/watch?v=NFoZPyQqVRA) **source**: Ramadhan"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1YtJE8vuA8cAX53zdjesD1-rqACmXm-Y3","timestamp":1721519314165}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
